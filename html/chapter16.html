<!DOCTYPE html>
<html lang="zh">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <base href="./">
    <title>ç¬¬16ç« ï¼šé¦–Tokenå»¶è¿Ÿ(TTFT)ä¼˜åŒ–</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="stylesheet" href="assets/highlight.css">
    <script src="assets/script.js" defer></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$']],
                displayMath: [['$$', '$$']],
                processEscapes: false,
                packages: {'[+]': ['noerrors', 'ams']}
            },
            options: {
                ignoreHtmlClass: 'tex2jax_ignore',
                processHtmlClass: 'tex2jax_process'
            },
            loader: {
                load: ['[tex]/noerrors', '[tex]/ams']
            }
        };
    </script>
</head>
<body>
    <div class="container">
        <nav id="sidebar" class="sidebar">
            <div class="sidebar-header">
                <h3>ç›®å½•</h3>
                <button id="sidebar-toggle" class="sidebar-toggle">
                    <span></span>
                    <span></span>
                    <span></span>
                </button>
            </div>
            <div class="sidebar-search">
                <input type="text" id="sidebar-search-input" placeholder="æœç´¢..." autocomplete="off">
            </div>
            <div id="tree-container">
                <nav class="tree-nav" role="tree">
                    <div class="tree-item " >
                        <a href="index.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">è¾¹ç¼˜ä¾§å¤§è¯­è¨€æ¨¡å‹æ¨ç†åŠ é€Ÿï¼šä»ç®—æ³•åˆ°ç³»ç»Ÿ</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter1.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬1ç« ï¼šè¾¹ç¼˜æ¨ç†çš„æŒ‘æˆ˜ä¸æœºé‡</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter2.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬2ç« ï¼šæ€§èƒ½åˆ†æä¸Rooflineæ¨¡å‹</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter3.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬3ç« ï¼šå°è¯­è¨€æ¨¡å‹(SLM)æ¦‚è§ˆ</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter4.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬4ç« ï¼šåè®­ç»ƒé‡åŒ–ï¼ˆPTQï¼‰</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter5.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬5ç« ï¼šHessianå¼•å¯¼çš„é‡åŒ–æ–¹æ³•</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter6.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬6ç« ï¼šæ—‹è½¬é‡åŒ–ä¸æä½æ¯”ç‰¹é‡åŒ–</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter7.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬7ç« ï¼šé‡åŒ–å‹å¥½çš„æ¨¡å‹è®¾è®¡</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter8.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬8ç« ï¼šé‡åŒ–å·¥å…·é“¾</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter9.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬9ç« ï¼šæ¨¡å‹å‰ªæ</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter10.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬10ç« ï¼šç¨€ç–åŒ–ä¸å‚æ•°å…±äº«</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter11.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬11ç« ï¼šåŠ¨æ€ç½‘ç»œæ¶æ„</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter12.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬12ç« ï¼šçŸ¥è¯†è’¸é¦</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter13.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬13ç« ï¼šæ³¨æ„åŠ›æœºåˆ¶ä¼˜åŒ–</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter14.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬14ç« ï¼šKV Cacheç®¡ç†ä¸å‹ç¼©</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter15.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬15ç« ï¼šè§£ç åŠ é€ŸæŠ€æœ¯</span>
                        </a>
                    </div>
                
                    <div class="tree-item active" >
                        <a href="chapter16.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬16ç« ï¼šé¦–Tokenå»¶è¿Ÿ(TTFT)ä¼˜åŒ–</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter17.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬17ç« ï¼šå†…å­˜ç®¡ç†ä¸Offloading</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter18.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬18ç« ï¼šè¾¹ç¼˜æ¨ç†æ¡†æ¶</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter19.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬19ç« ï¼šæ·±åº¦å­¦ä¹ ç¼–è¯‘å™¨</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter20.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬20ç« ï¼šç¡¬ä»¶ç‰¹å®šä¼˜åŒ–</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter21.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬21ç« ï¼šè·¨å¹³å°éƒ¨ç½²å®è·µ</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter22.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬22ç« ï¼šè§†è§‰ç¼–ç å™¨ä¼˜åŒ–</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter23.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬23ç« ï¼šå¤šæ¨¡æ€èåˆä¸å¹³è¡¡</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter24.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬24ç« ï¼šå®æ—¶è¯­éŸ³åœºæ™¯ä¼˜åŒ–</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter25.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬25ç« ï¼šç¥ç»æ¶æ„æœç´¢ï¼ˆNASï¼‰</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="chapter26.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">ç¬¬26ç« ï¼šæœªæ¥æŠ€æœ¯å±•æœ›</span>
                        </a>
                    </div>
                
                    <div class="tree-item " >
                        <a href="CLAUDE.html" class="tree-link">
                            <span class="tree-icon">ğŸ“„</span>
                            <span class="tree-title">é¡¹ç›®è¯´æ˜</span>
                        </a>
                    </div>
                </nav>
            </div>
        </nav>
        
        <main class="content">
            <article>
                <h1 id="16tokenttft">ç¬¬16ç« ï¼šé¦–Tokenå»¶è¿Ÿ(TTFT)ä¼˜åŒ–</h1>
<p>åœ¨å¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†æœåŠ¡ä¸­ï¼Œé¦–Tokenå»¶è¿Ÿï¼ˆTime To First Token, TTFTï¼‰æ˜¯å½±å“ç”¨æˆ·ä½“éªŒçš„å…³é”®æŒ‡æ ‡ã€‚TTFTæŒ‡ä»ç”¨æˆ·å‘é€è¯·æ±‚åˆ°æ¨¡å‹ç”Ÿæˆç¬¬ä¸€ä¸ªè¾“å‡ºtokençš„æ—¶é—´é—´éš”ã€‚æœ¬ç« æ·±å…¥æ¢è®¨TTFTçš„ä¼˜åŒ–æŠ€æœ¯ï¼Œä»ç†è®ºåˆ†æåˆ°å·¥ç¨‹å®è·µï¼Œå¸®åŠ©è¯»è€…æŒæ¡é™ä½é¦–Tokenå»¶è¿Ÿçš„æ ¸å¿ƒæ–¹æ³•ã€‚</p>
<h2 id="161-ttft">16.1 TTFTçš„å…³é”®å½±å“å› ç´ </h2>
<p>é¦–Tokenå»¶è¿Ÿæ˜¯ç”¨æˆ·ä½“éªŒçš„ç¬¬ä¸€é“é—¨æ§›ã€‚ç†è§£å…¶æ„æˆå’Œå½±å“å› ç´ æ˜¯ä¼˜åŒ–çš„åŸºç¡€ã€‚TTFTä¸ä»…ä»…æ˜¯ç®€å•çš„è®¡ç®—å»¶è¿Ÿï¼Œè¿˜æ¶‰åŠå†…å­˜è®¿é—®ã€æ•°æ®ä¼ è¾“ã€è°ƒåº¦å¼€é”€ç­‰å¤šä¸ªç»´åº¦ã€‚</p>
<h3 id="1611-ttft">16.1.1 TTFTçš„ç»„æˆåˆ†æ</h3>
<p>TTFTå¯ä»¥åˆ†è§£ä¸ºä»¥ä¸‹å‡ ä¸ªä¸»è¦ç»„æˆéƒ¨åˆ†ï¼š</p>
<ol>
<li><strong>è¾“å…¥é¢„å¤„ç†æ—¶é—´ï¼ˆT_preprocessï¼‰</strong></li>
</ol>
<p>å¯¹äºæ–‡æœ¬è¾“å…¥ï¼Œé¢„å¤„ç†åŒ…æ‹¬ï¼š</p>
<ul>
<li>Tokenizationï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºtokenåºåˆ—</li>
<li>EmbeddingæŸ¥æ‰¾ï¼šå°†token IDæ˜ å°„åˆ°embeddingå‘é‡</li>
<li>ä½ç½®ç¼–ç ï¼šæ·»åŠ ä½ç½®ä¿¡æ¯</li>
</ul>
<p>æ•°å­¦è¡¨ç¤ºï¼š</p>
<pre class="codehilite"><code>T_preprocess = T_tokenize + T_embed + T_position
</code></pre>

<p>å…¶ä¸­embeddingæŸ¥æ‰¾çš„æ—¶é—´å¤æ‚åº¦ä¸ºO(n)ï¼Œnä¸ºè¾“å…¥åºåˆ—é•¿åº¦ã€‚å¯¹äºè¯è¡¨å¤§å°ä¸ºVï¼Œembeddingç»´åº¦ä¸ºdçš„æ¨¡å‹ï¼Œéœ€è¦è®¿é—®çš„å†…å­˜é‡ä¸ºï¼š</p>
<pre class="codehilite"><code>M_embed = n Ã— d Ã— sizeof(float)
</code></pre>

<p>å®é™…æµ‹é‡æ•°æ®æ˜¾ç¤ºï¼Œå¯¹äºå…¸å‹çš„LLMï¼ˆå¦‚Llama-2 7Bï¼‰ï¼Œtokenizationçº¦å é¢„å¤„ç†æ—¶é—´çš„15-20%ï¼ŒembeddingæŸ¥æ‰¾å 60-70%ï¼Œä½ç½®ç¼–ç å 10-15%ã€‚åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šï¼Œç”±äºå†…å­˜å¸¦å®½é™åˆ¶ï¼ŒembeddingæŸ¥æ‰¾å¾€å¾€æˆä¸ºç“¶é¢ˆã€‚</p>
<p>ä¼˜åŒ–æœºä¼šåˆ†æï¼š</p>
<ul>
<li>Tokenizationå¯é€šè¿‡é¢„ç¼–è¯‘çš„æœ‰é™çŠ¶æ€æœºï¼ˆFSMï¼‰åŠ é€Ÿ</li>
<li>EmbeddingæŸ¥æ‰¾å¯åˆ©ç”¨ç¨€ç–è®¿é—®æ¨¡å¼ä¼˜åŒ–ç¼“å­˜</li>
<li>ä½ç½®ç¼–ç å¯é¢„è®¡ç®—å¹¶å­˜å‚¨ï¼Œç‰¹åˆ«æ˜¯å¯¹äºRoPEç­‰ç›¸å¯¹ä½ç½®ç¼–ç </li>
</ul>
<ol start="2">
<li><strong>é¢„å¡«å……è®¡ç®—æ—¶é—´ï¼ˆT_prefillï¼‰</strong></li>
</ol>
<p>é¢„å¡«å……é˜¶æ®µéœ€è¦å¤„ç†æ•´ä¸ªè¾“å…¥åºåˆ—ï¼Œç”Ÿæˆæ‰€æœ‰ä½ç½®çš„KV Cacheã€‚å¯¹äºTransformeræ¶æ„ï¼Œä¸»è¦è®¡ç®—åŒ…æ‹¬ï¼š</p>
<ul>
<li>Self-Attentionè®¡ç®—ï¼š</li>
</ul>
<pre class="codehilite"><code>FLOPs_attention = 2 Ã— nÂ² Ã— d + 4 Ã— n Ã— dÂ²
</code></pre>

<p>å…¶ä¸­ç¬¬ä¸€é¡¹ä¸ºQK^Tè®¡ç®—ï¼Œç¬¬äºŒé¡¹ä¸ºæ³¨æ„åŠ›æƒé‡ä¸Vçš„çŸ©é˜µä¹˜æ³•</p>
<ul>
<li>FFNè®¡ç®—ï¼š</li>
</ul>
<pre class="codehilite"><code>FLOPs_ffn = 8 Ã— n Ã— d Ã— d_ffn
</code></pre>

<p>é€šå¸¸d_ffn = 4d</p>
<ul>
<li>æ€»è®¡ç®—é‡ï¼ˆLå±‚ï¼‰ï¼š</li>
</ul>
<pre class="codehilite"><code>FLOPs_total = L Ã— (FLOPs_attention + FLOPs_ffn)
</code></pre>

<p>è¯¦ç»†çš„è®¡ç®—åˆ†è§£ï¼š</p>
<ul>
<li>QKVæŠ•å½±ï¼š3 Ã— 2 Ã— n Ã— d Ã— d = 6ndÂ² FLOPs</li>
<li>Attention scoresï¼š2 Ã— nÂ² Ã— d FLOPsï¼ˆåŒ…å«ç¼©æ”¾ï¼‰</li>
<li>Softmaxï¼šçº¦3nÂ² FLOPsï¼ˆexpã€sumã€divï¼‰</li>
<li>Attentionè¾“å‡ºï¼š2 Ã— nÂ² Ã— d FLOPs</li>
<li>è¾“å‡ºæŠ•å½±ï¼š2 Ã— n Ã— d Ã— d = 2ndÂ² FLOPs</li>
<li>FFNä¸ŠæŠ•å½±ï¼š2 Ã— n Ã— d Ã— 4d = 8ndÂ² FLOPs</li>
<li>FFNä¸‹æŠ•å½±ï¼š2 Ã— n Ã— 4d Ã— d = 8ndÂ² FLOPs</li>
<li>æ¿€æ´»å‡½æ•°ï¼ˆGELU/SwiGLUï¼‰ï¼šçº¦4nd FLOPs</li>
</ul>
<p>å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œå½“nè¾ƒå°æ—¶ï¼ˆå¦‚n &lt; d/32ï¼‰ï¼ŒFFNè®¡ç®—å ä¸»å¯¼ï¼›å½“nè¾ƒå¤§æ—¶ï¼ŒAttentionçš„O(nÂ²)å¤æ‚åº¦ä½¿å…¶æˆä¸ºç“¶é¢ˆã€‚è¿™ä¸ªè½¬æŠ˜ç‚¹å¯¹äºé€‰æ‹©ä¼˜åŒ–ç­–ç•¥è‡³å…³é‡è¦ã€‚</p>
<ol start="3">
<li><strong>é¦–Tokenç”Ÿæˆæ—¶é—´ï¼ˆT_generateï¼‰</strong></li>
</ol>
<p>ç”Ÿæˆç¬¬ä¸€ä¸ªtokenéœ€è¦ï¼š</p>
<ul>
<li>æœ€åä¸€å±‚çš„å‰å‘ä¼ æ’­</li>
<li>Logitsè®¡ç®—å’Œé‡‡æ ·</li>
<li>Tokenè§£ç </li>
</ul>
<p>å…·ä½“è®¡ç®—æˆæœ¬ï¼š</p>
<ul>
<li>æœ€åä½ç½®çš„æ³¨æ„åŠ›ï¼š2 Ã— L Ã— dÂ² FLOPsï¼ˆä»…å¤„ç†æœ€åä¸€ä¸ªtokenï¼‰</li>
<li>LogitsæŠ•å½±ï¼š2 Ã— d Ã— V FLOPsï¼ˆVä¸ºè¯è¡¨å¤§å°ï¼‰</li>
<li>Softmaxè®¡ç®—ï¼š3V FLOPs</li>
<li>é‡‡æ ·ç®—æ³•å¼€é”€ï¼š</li>
<li>Greedyï¼šO(V)</li>
<li>Top-kï¼šO(V log k)</li>
<li>Top-pï¼šO(V log V)ï¼ˆæœ€åæƒ…å†µï¼‰</li>
</ul>
<ol start="4">
<li><strong>ç³»ç»Ÿå¼€é”€ï¼ˆT_overheadï¼‰</strong></li>
</ol>
<p>åŒ…æ‹¬ï¼š</p>
<ul>
<li>å†…å­˜åˆ†é…å’Œåˆå§‹åŒ–</li>
<li>æ•°æ®ä¼ è¾“ï¼ˆCPU-GPUï¼‰</li>
<li>è°ƒåº¦å’ŒåŒæ­¥å¼€é”€</li>
</ul>
<p>å…¸å‹çš„ç³»ç»Ÿå¼€é”€æµ‹é‡ï¼š</p>
<ul>
<li>å†…å­˜åˆ†é…ï¼š1-5msï¼ˆå–å†³äºåˆ†é…å™¨å’Œç¢ç‰‡æƒ…å†µï¼‰</li>
<li>CPU-GPUä¼ è¾“ï¼š</li>
<li>PCIe Gen3 x16ï¼šçº¦15.8 GB/s</li>
<li>PCIe Gen4 x16ï¼šçº¦31.5 GB/s</li>
<li>ç»Ÿä¸€å†…å­˜æ¶æ„ï¼ˆå¦‚Apple Mç³»åˆ—ï¼‰ï¼šæ¥è¿‘0</li>
<li>å†…æ ¸å¯åŠ¨å¼€é”€ï¼šæ¯ä¸ªkernelçº¦10-50Î¼s</li>
<li>åŒæ­¥å¼€é”€ï¼š10-100Î¼sï¼ˆå–å†³äºå¹¶å‘ç¨‹åº¦ï¼‰</li>
</ul>
<p>æ€»TTFTå¯è¡¨ç¤ºä¸ºï¼š</p>
<pre class="codehilite"><code>TTFT = T_preprocess + T_prefill + T_generate + T_overhead
</code></pre>

<p>åœ¨å®é™…ç³»ç»Ÿä¸­ï¼Œå„éƒ¨åˆ†çš„å…¸å‹å æ¯”ï¼š</p>
<ul>
<li>çŸ­åºåˆ—ï¼ˆ&lt;128 tokensï¼‰ï¼šT_overheadå 20-30%</li>
<li>ä¸­ç­‰åºåˆ—ï¼ˆ128-512 tokensï¼‰ï¼šT_prefillå 70-80%</li>
<li>é•¿åºåˆ—ï¼ˆ&gt;512 tokensï¼‰ï¼šT_prefillå 90%ä»¥ä¸Š</li>
</ul>
<h3 id="1612">16.1.2 é¢„å¡«å……é˜¶æ®µçš„è®¡ç®—ç‰¹æ€§</h3>
<p>é¢„å¡«å……é˜¶æ®µå…·æœ‰ç‹¬ç‰¹çš„è®¡ç®—ç‰¹æ€§ï¼Œä¸åŒäºè‡ªå›å½’ç”Ÿæˆé˜¶æ®µï¼š</p>
<ol>
<li><strong>å¹¶è¡Œæ€§ç‰¹å¾</strong></li>
</ol>
<p>é¢„å¡«å……å¯ä»¥å¹¶è¡Œå¤„ç†æ‰€æœ‰è¾“å…¥tokenï¼š</p>
<ul>
<li>åºåˆ—ç»´åº¦å¹¶è¡Œï¼šæ‰€æœ‰ä½ç½®åŒæ—¶è®¡ç®—</li>
<li>æ‰¹å¤„ç†å¹¶è¡Œï¼šå¤šä¸ªè¯·æ±‚å¯ä»¥åˆå¹¶å¤„ç†</li>
<li>ç®—å­å†…å¹¶è¡Œï¼šçŸ©é˜µä¹˜æ³•çš„å¤©ç„¶å¹¶è¡Œæ€§</li>
</ul>
<p>å¹¶è¡Œæ•ˆç‡åˆ†æï¼š</p>
<pre class="codehilite"><code>Parallel_efficiency = Useful_work / (Useful_work + Synchronization_overhead)
</code></pre>

<p>å¯¹äºä¸åŒçš„å¹¶è¡Œç²’åº¦ï¼š</p>
<ul>
<li>Tokençº§å¹¶è¡Œï¼šæ•ˆç‡ &gt; 95%ï¼ˆç»†ç²’åº¦ï¼ŒåŒæ­¥å¼€é”€å°ï¼‰</li>
<li>Layerçº§å¹¶è¡Œï¼šæ•ˆç‡ 80-90%ï¼ˆéœ€è¦è·¨å±‚åŒæ­¥ï¼‰</li>
<li>Modelå¹¶è¡Œï¼šæ•ˆç‡ 60-80%ï¼ˆé€šä¿¡å¼€é”€å¤§ï¼‰</li>
</ul>
<ol start="2">
<li><strong>å†…å­˜è®¿é—®æ¨¡å¼</strong></li>
</ol>
<p>é¢„å¡«å……çš„å†…å­˜è®¿é—®å‘ˆç°ä»¥ä¸‹ç‰¹ç‚¹ï¼š</p>
<ul>
<li>å¤§é‡çš„çŸ©é˜µä¹˜æ³•æ“ä½œï¼Œé€‚åˆGPUåŠ é€Ÿ</li>
<li>KV Cacheçš„è¿ç»­å†™å…¥ï¼Œå¯¹å†…å­˜å¸¦å®½è¦æ±‚é«˜</li>
<li>AttentionçŸ©é˜µçš„ä¸´æ—¶å­˜å‚¨éœ€æ±‚ï¼šO(nÂ²)</li>
</ul>
<p>å…·ä½“çš„å†…å­˜è®¿é—®æ¨¡å¼åˆ†æï¼š</p>
<pre class="codehilite"><code>æƒé‡è¯»å–æ¨¡å¼ï¼šSequential, Read-only, Reusable
æ¿€æ´»å€¼æ¨¡å¼ï¼šStreaming, Read-write, Temporary
KV Cacheæ¨¡å¼ï¼šSequential write, Persistent
AttentionçŸ©é˜µï¼šBlock-wise, High locality
</code></pre>

<p>å†…å­˜è®¿é—®ä¼˜åŒ–çš„å…³é”®æŒ‡æ ‡ï¼š</p>
<ul>
<li>Cacheå‘½ä¸­ç‡ï¼šç†æƒ³æƒ…å†µ &gt; 90%</li>
<li>å†…å­˜å¸¦å®½åˆ©ç”¨ç‡ï¼šç›®æ ‡ &gt; 80%</li>
<li>Bankå†²çªç‡ï¼šåº” &lt; 5%</li>
</ul>
<ol start="3">
<li><strong>è®¡ç®—å¯†åº¦åˆ†æ</strong></li>
</ol>
<p>å®šä¹‰è®¡ç®—å¯†åº¦ï¼ˆArithmetic Intensityï¼‰ä¸ºï¼š</p>
<pre class="codehilite"><code>AI = FLOPs / Memory_Access
</code></pre>

<p>å¯¹äºä¸åŒçš„æ“ä½œï¼š</p>
<ul>
<li>QK^Tè®¡ç®—ï¼šAI â‰ˆ n/8ï¼ˆéšåºåˆ—é•¿åº¦å¢åŠ ï¼‰</li>
<li>FFNè®¡ç®—ï¼šAI â‰ˆ d_ffn/12 â‰ˆ d/3ï¼ˆå›ºå®šå€¼ï¼‰</li>
</ul>
<p>å½“nè¾ƒå¤§æ—¶ï¼Œæ³¨æ„åŠ›è®¡ç®—æˆä¸ºcompute-boundï¼›å½“nè¾ƒå°æ—¶ï¼Œæ•´ä½“å‘ˆç°memory-boundç‰¹æ€§ã€‚</p>
<p>æ›´è¯¦ç»†çš„è®¡ç®—å¯†åº¦åˆ†æï¼š</p>
<p>å¯¹äºAttentionå±‚ï¼š</p>
<pre class="codehilite"><code>FLOPs_attn = 2nÂ²d + 4ndÂ²
Memory_attn = 12nd Ã— sizeof(fp16) + nÂ² Ã— sizeof(fp16)
AI_attn = (2nÂ²d + 4ndÂ²) / (12nd + nÂ²) Ã— 2
        â‰ˆ n/6 + 2d/3  (å½“n &gt;&gt; dæ—¶)
        â‰ˆ 2d/3        (å½“n &lt;&lt; dæ—¶)
</code></pre>

<p>å¯¹äºFFNå±‚ï¼š</p>
<pre class="codehilite"><code>FLOPs_ffn = 16ndÂ²
Memory_ffn = 2nd Ã— sizeof(fp16) + 32dÂ² Ã— sizeof(fp16)
AI_ffn = 16ndÂ² / (2nd + 32dÂ²) Ã— 2
       â‰ˆ 16d / (2 + 32d/n)
       â‰ˆ d/2  (å½“n &gt;&gt; dæ—¶)
</code></pre>

<p>å…³é”®æ´å¯Ÿï¼š</p>
<ul>
<li>å½“AI &lt; 10æ—¶ï¼Œé€šå¸¸æ˜¯memory-boundï¼ˆè¾¹ç¼˜GPUï¼‰</li>
<li>å½“AI &gt; 50æ—¶ï¼Œé€šå¸¸æ˜¯compute-bound</li>
<li>10 &lt; AI &lt; 50æ˜¯å¹³è¡¡åŒºé—´ï¼Œä¼˜åŒ–ç©ºé—´æœ€å¤§</li>
</ul>
<h3 id="1613">16.1.3 å†…å­˜å¸¦å®½ä¸è®¡ç®—å¼ºåº¦çš„æƒè¡¡</h3>
<p>åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šï¼Œå†…å­˜å¸¦å®½å¾€å¾€æ˜¯ç“¶é¢ˆã€‚åˆ†æå†…å­˜è®¿é—®æ¨¡å¼å¯¹ä¼˜åŒ–è‡³å…³é‡è¦ã€‚</p>
<ol>
<li><strong>å¸¦å®½éœ€æ±‚è®¡ç®—</strong></li>
</ol>
<p>å¯¹äºæ‰¹å¤§å°ä¸ºBï¼Œåºåˆ—é•¿åº¦ä¸ºnçš„é¢„å¡«å……ï¼š</p>
<ul>
<li>æƒé‡è¯»å–ï¼š<code>L Ã— (12 Ã— dÂ² + 2 Ã— d Ã— d_ffn) Ã— sizeof(weight)</code></li>
<li>æ¿€æ´»å€¼è¯»å†™ï¼š<code>2 Ã— B Ã— n Ã— d Ã— L Ã— sizeof(activation)</code></li>
<li>KV Cacheå†™å…¥ï¼š<code>2 Ã— B Ã— n Ã— d Ã— L Ã— sizeof(cache)</code></li>
</ul>
<p>æ€»å¸¦å®½éœ€æ±‚ï¼š</p>
<pre class="codehilite"><code>BW_required = (Weight_Access + Activation_Access + Cache_Access) / T_compute
</code></pre>

<p>å…·ä½“è®¡ç®—ç¤ºä¾‹ï¼ˆLlama-2 7B, B=1, n=512ï¼‰ï¼š</p>
<pre class="codehilite"><code>æƒé‡å¤§å°ï¼šçº¦13GBï¼ˆFP16ï¼‰
æƒé‡è¯»å–ï¼š13GB Ã— (n/é‡ç”¨å› å­) â‰ˆ 13GB
æ¿€æ´»å€¼ï¼š2 Ã— 1 Ã— 512 Ã— 4096 Ã— 32 Ã— 2B = 268MB
KV Cacheï¼š2 Ã— 1 Ã— 512 Ã— 4096 Ã— 32 Ã— 2B = 268MB

å‡è®¾100msè®¡ç®—æ—¶é—´ï¼š
BW_required â‰ˆ (13GB + 0.268GB + 0.268GB) / 0.1s â‰ˆ 135.4 GB/s
</code></pre>

<p>è¿™è§£é‡Šäº†ä¸ºä»€ä¹ˆè¾¹ç¼˜è®¾å¤‡ï¼ˆå…¸å‹å¸¦å®½20-100 GB/sï¼‰åœ¨å¤„ç†LLMæ—¶é¢ä¸´æŒ‘æˆ˜ã€‚</p>
<ol start="2">
<li><strong>Rooflineæ¨¡å‹åˆ†æ</strong></li>
</ol>
<p>æ ¹æ®è®¾å¤‡çš„è®¡ç®—å³°å€¼æ€§èƒ½P_maxå’Œå†…å­˜å¸¦å®½BW_maxï¼š</p>
<ul>
<li>å¦‚æœ AI &lt; P_max/BW_maxï¼Œåˆ™ä¸ºmemory-bound</li>
<li>å¦åˆ™ä¸ºcompute-bound</li>
</ul>
<p>å¯¹äºå…¸å‹çš„è¾¹ç¼˜GPUï¼ˆå¦‚Mali G78ï¼‰ï¼š</p>
<ul>
<li>P_max â‰ˆ 1 TFLOPS (FP16)</li>
<li>BW_max â‰ˆ 50 GB/s</li>
<li>ä¸´ç•ŒAI â‰ˆ 20 FLOPs/Byte</li>
</ul>
<p>è¿™æ„å‘³ç€å½“åºåˆ—é•¿åº¦n &lt; 160æ—¶ï¼Œé¢„å¡«å……é€šå¸¸æ˜¯memory-boundçš„ã€‚</p>
<p>æ›´å¤šè¾¹ç¼˜ç¡¬ä»¶çš„Rooflineç‰¹å¾ï¼š</p>
<p>| ç¡¬ä»¶ | å³°å€¼æ€§èƒ½(FP16) | å†…å­˜å¸¦å®½ | ä¸´ç•ŒAI | Memory-boundé˜ˆå€¼ |</p>
<table>
<thead>
<tr>
<th>ç¡¬ä»¶</th>
<th>å³°å€¼æ€§èƒ½(FP16)</th>
<th>å†…å­˜å¸¦å®½</th>
<th>ä¸´ç•ŒAI</th>
<th>Memory-boundé˜ˆå€¼</th>
</tr>
</thead>
<tbody>
<tr>
<td>Snapdragon 8 Gen 3 GPU</td>
<td>2.1 TFLOPS</td>
<td>77 GB/s</td>
<td>27.3</td>
<td>n &lt; 218</td>
</tr>
<tr>
<td>Apple A17 Pro Neural Engine</td>
<td>35 TOPS</td>
<td>100 GB/s</td>
<td>350</td>
<td>n &lt; 2800</td>
</tr>
<tr>
<td>NVIDIA Jetson Orin</td>
<td>40 TFLOPS</td>
<td>204.8 GB/s</td>
<td>195</td>
<td>n &lt; 1560</td>
</tr>
<tr>
<td>Intel Arc A370M</td>
<td>8 TFLOPS</td>
<td>112 GB/s</td>
<td>71.4</td>
<td>n &lt; 571</td>
</tr>
</tbody>
</table>
<p>ä¼˜åŒ–ç­–ç•¥é€‰æ‹©æµç¨‹ï¼š</p>
<pre class="codehilite"><code>if (n &lt; Memory_bound_threshold):
    # Memory-boundä¼˜åŒ–

    - ç®—å­èåˆå‡å°‘å†…å­˜è®¿é—®
    - æ•°æ®å¸ƒå±€ä¼˜åŒ–
    - ç¼“å­˜ä¼˜åŒ–
else:
    # Compute-boundä¼˜åŒ–  

    - æ··åˆç²¾åº¦è®¡ç®—
    - ç¨€ç–åŒ–åŠ é€Ÿ
    - å¹¶è¡Œåº¦æå‡
</code></pre>

<ol start="3">
<li><strong>ä¼˜åŒ–ç­–ç•¥é€‰æ‹©</strong></li>
</ol>
<p>åŸºäºä¸Šè¿°åˆ†æï¼š</p>
<ul>
<li>Memory-boundåœºæ™¯ï¼šé‡ç‚¹ä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼ï¼Œå‡å°‘æ•°æ®ä¼ è¾“</li>
<li>Compute-boundåœºæ™¯ï¼šæé«˜è®¡ç®—å¹¶è¡Œåº¦ï¼Œä½¿ç”¨æ··åˆç²¾åº¦</li>
</ul>
<h3 id="1614-ttft">16.1.4 æ‰¹å¤„ç†å¯¹TTFTçš„å½±å“</h3>
<p>æ‰¹å¤„ç†æ˜¯æé«˜ååé‡çš„å…³é”®æŠ€æœ¯ï¼Œä½†å¯¹TTFTæœ‰å¤æ‚å½±å“ã€‚</p>
<ol>
<li><strong>æ‰¹å¤„ç†çš„æ”¶ç›Šåˆ†æ</strong></li>
</ol>
<p>æ‰¹å¤§å°ä¸ºBæ—¶ï¼š</p>
<ul>
<li>æƒé‡è¯»å–å‡æ‘Šï¼šæ¯ä¸ªè¯·æ±‚çš„æƒé‡è¯»å–æˆæœ¬é™ä¸º1/B</li>
<li>GPUåˆ©ç”¨ç‡æå‡ï¼šæ›´å¥½åœ°éšè—å†…å­˜å»¶è¿Ÿ</li>
<li>è®¡ç®—æ•ˆç‡æé«˜ï¼šçŸ©é˜µä¹˜æ³•çš„ç»´åº¦å¢å¤§</li>
</ul>
<p>å®šé‡åˆ†ææ‰¹å¤„ç†æ•ˆç‡æå‡ï¼š</p>
<p>å•è¯·æ±‚æ•ˆç‡ï¼š</p>
<pre class="codehilite"><code>Efficiency_single = Actual_FLOPS / Peak_FLOPS
                  â‰ˆ 1 / (1 + Memory_stall_ratio)
                  â‰ˆ 1 / (1 + BW_required/BW_max Ã— (1 - cache_hit_rate))
</code></pre>

<p>æ‰¹å¤„ç†æ•ˆç‡ï¼š</p>
<pre class="codehilite"><code>Efficiency_batch = 1 / (1 + Memory_stall_ratio/B)
                 â‰ˆ 1 / (1 + (BW_required/B)/BW_max Ã— (1 - cache_hit_rate))
</code></pre>

<p>æ•ˆç‡æå‡æ¯”ï¼š</p>
<pre class="codehilite"><code>Speedup = Efficiency_batch / Efficiency_single
        â‰ˆ (1 + Memory_stall_ratio) / (1 + Memory_stall_ratio/B)
</code></pre>

<p>å®é™…æµ‹é‡æ•°æ®ï¼ˆLlama-2 7B on Mali G78ï¼‰ï¼š</p>
<ul>
<li>B=1: æ•ˆç‡çº¦35%</li>
<li>B=4: æ•ˆç‡çº¦68%</li>
<li>B=8: æ•ˆç‡çº¦82%</li>
<li>B=16: æ•ˆç‡çº¦89%ï¼ˆæ¥è¿‘é¥±å’Œï¼‰</li>
</ul>
<ol start="2">
<li><strong>æ‰¹å¤„ç†çš„æˆæœ¬</strong></li>
</ol>
<ul>
<li>ç­‰å¾…æ—¶é—´ï¼šéœ€è¦ç§¯ç´¯è¶³å¤Ÿçš„è¯·æ±‚</li>
<li>å†…å­˜å ç”¨ï¼šçº¿æ€§å¢é•¿çš„æ¿€æ´»å€¼å’ŒKV Cache</li>
<li>é•¿å°¾æ•ˆåº”ï¼šæ‰¹å†…æœ€é•¿åºåˆ—å†³å®šæ•´ä½“å»¶è¿Ÿ</li>
</ul>
<p>å…·ä½“æˆæœ¬åˆ†æï¼š</p>
<p>å†…å­˜å ç”¨å¢é•¿ï¼š</p>
<pre class="codehilite"><code>Memory_batch = B Ã— (n Ã— d Ã— L Ã— 2 + KV_cache_size)
             = B Ã— n Ã— d Ã— L Ã— 4 Ã— sizeof(fp16)
</code></pre>

<p>å¯¹äº7Bæ¨¡å‹ï¼Œæ¯å¢åŠ 1ä¸ªè¯·æ±‚ï¼ˆn=512ï¼‰ï¼š</p>
<ul>
<li>é¢å¤–å†…å­˜ï¼š512 Ã— 4096 Ã— 32 Ã— 4 Ã— 2B = 536MB</li>
<li>è¾¹ç¼˜è®¾å¤‡ï¼ˆ8GB RAMï¼‰æœ€å¤§æ‰¹ï¼šçº¦8-10</li>
</ul>
<p>é•¿å°¾æ•ˆåº”çš„é‡åŒ–ï¼š</p>
<pre class="codehilite"><code>TTFT_batch = max(TTFT_i for i in batch)
Efficiency_loss = (avg(n_i) / max(n_i)) Ã— 100%
</code></pre>

<p>å®æµ‹æ•°æ®æ˜¾ç¤ºï¼Œåºåˆ—é•¿åº¦å·®å¼‚è¾ƒå¤§æ—¶ï¼Œæ•ˆç‡æŸå¤±å¯è¾¾30-50%ã€‚</p>
<ol start="3">
<li><strong>åŠ¨æ€æ‰¹å¤„ç†ç­–ç•¥</strong></li>
</ol>
<p>ä¸ºå¹³è¡¡TTFTå’Œååé‡ï¼Œå¯é‡‡ç”¨ï¼š</p>
<ul>
<li>æ—¶é—´çª—å£ç­–ç•¥ï¼šç­‰å¾…æ—¶é—´ä¸è¶…è¿‡T_max</li>
<li>è‡ªé€‚åº”æ‰¹å¤§å°ï¼šæ ¹æ®å½“å‰è´Ÿè½½åŠ¨æ€è°ƒæ•´</li>
<li>ä¼˜å…ˆçº§è°ƒåº¦ï¼šå¯¹å»¶è¿Ÿæ•æ„Ÿçš„è¯·æ±‚ä¼˜å…ˆå¤„ç†</li>
</ul>
<p>è¯¦ç»†ç­–ç•¥è®¾è®¡ï¼š</p>
<p>æ—¶é—´çª—å£è‡ªé€‚åº”ï¼š</p>
<pre class="codehilite"><code>T_window = min(T_max, max(T_min, Î± Ã— avg_TTFT + Î² Ã— std_TTFT))
</code></pre>

<p>å…¶ä¸­Î±=1.0, Î²=2.0ä¿è¯95%è¯·æ±‚çš„TTFTåœ¨åˆç†èŒƒå›´ã€‚</p>
<p>è´Ÿè½½æ„ŸçŸ¥çš„æ‰¹å¤§å°ï¼š</p>
<pre class="codehilite"><code>B_adaptive = {
    1,    if load &lt; 0.3     # ä½è´Ÿè½½ï¼Œä¼˜å…ˆå»¶è¿Ÿ
    4,    if 0.3 â‰¤ load &lt; 0.6
    8,    if 0.6 â‰¤ load &lt; 0.8
    16,   if load â‰¥ 0.8     # é«˜è´Ÿè½½ï¼Œä¼˜å…ˆååé‡
}
</code></pre>

<p>ä¼˜å…ˆçº§è°ƒåº¦ç®—æ³•ï¼š</p>
<pre class="codehilite"><code>priority = w1 Ã— (current_time - arrival_time) + 
           w2 Ã— (1 / expected_latency) +
           w3 Ã— user_priority
</code></pre>

<ol start="4">
<li><strong>æ•°å­¦å»ºæ¨¡</strong></li>
</ol>
<p>è®¾è¯·æ±‚åˆ°è¾¾ç‡ä¸ºÎ»ï¼Œæ‰¹å¤„ç†ç­‰å¾…æ—¶é—´ä¸ºt_waitï¼Œåˆ™ï¼š</p>
<ul>
<li>å¹³å‡æ‰¹å¤§å°ï¼šE[B] = Î» Ã— t_wait</li>
<li>è®¡ç®—æ—¶é—´ï¼šT_compute(B) = Î± + Î² Ã— Bï¼ˆÎ±ä¸ºå›ºå®šå¼€é”€ï¼ŒÎ²ä¸ºè¾¹é™…æˆæœ¬ï¼‰</li>
<li>æœ€ä¼˜ç­‰å¾…æ—¶é—´ï¼št_wait* = argmin(t_wait + T_compute(Î» Ã— t_wait))</li>
</ul>
<p>é€šè¿‡æ±‚å¯¼å¯å¾—ï¼š</p>
<pre class="codehilite"><code>t_wait* = sqrt(Î± / (Î² Ã— Î»))
</code></pre>

<p>è¿™æä¾›äº†æ‰¹å¤„ç†å‚æ•°è®¾ç½®çš„ç†è®ºæŒ‡å¯¼ã€‚</p>
<p>å®é™…åº”ç”¨ç¤ºä¾‹ï¼š</p>
<ul>
<li>Î± = 20msï¼ˆå›ºå®šå¼€é”€ï¼‰</li>
<li>Î² = 5msï¼ˆæ¯è¯·æ±‚è¾¹é™…æˆæœ¬ï¼‰</li>
<li>Î» = 10 req/sï¼ˆå¹³å‡åˆ°è¾¾ç‡ï¼‰</li>
<li>t_wait* = sqrt(20/(5Ã—10)) = 0.63s</li>
<li>æœ€ä¼˜æ‰¹å¤§å°ï¼šçº¦6.3</li>
</ul>
<p>è€ƒè™‘åˆ°å®é™…çº¦æŸï¼Œå¯è®¾ç½®ä¸º6æˆ–è€…8ã€‚</p>
<h2 id="162">16.2 é¢„å¡«å……ä¼˜åŒ–æŠ€æœ¯</h2>
<p>é¢„å¡«å……é˜¶æ®µå æ®äº†TTFTçš„ä¸»è¦éƒ¨åˆ†ï¼Œå…¶ä¼˜åŒ–ç›´æ¥å†³å®šäº†ç”¨æˆ·ä½“éªŒã€‚æœ¬èŠ‚æ¢è®¨ä»ç®—æ³•åˆ°ç³»ç»Ÿå±‚é¢çš„å„ç§ä¼˜åŒ–æŠ€æœ¯ã€‚</p>
<h3 id="1621">16.2.1 å¹¶è¡ŒåŒ–ç­–ç•¥</h3>
<p>é¢„å¡«å……çš„å¹¶è¡Œä¼˜åŒ–å¯ä»¥ä»å¤šä¸ªç»´åº¦å±•å¼€ï¼Œå…³é”®æ˜¯è¯†åˆ«å¹¶åˆ©ç”¨è®¡ç®—çš„ç‹¬ç«‹æ€§ã€‚</p>
<ol>
<li><strong>åºåˆ—çº§å¹¶è¡Œ</strong></li>
</ol>
<p>Transformerçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶å…è®¸åºåˆ—å†…æ‰€æœ‰ä½ç½®å¹¶è¡Œè®¡ç®—ï¼š</p>
<ul>
<li>å¹¶è¡Œåº¦åˆ†æï¼š</li>
</ul>
<pre class="codehilite"><code>Parallelism_seq = min(n, P_cores)
</code></pre>

<p>å…¶ä¸­nä¸ºåºåˆ—é•¿åº¦ï¼ŒP_coresä¸ºå¯ç”¨è®¡ç®—æ ¸å¿ƒæ•°</p>
<ul>
<li>
<p>å·¥ä½œè´Ÿè½½åˆ†é…ï¼š
  æ¯ä¸ªè®¡ç®—å•å…ƒå¤„ç†n/Pä¸ªä½ç½®ï¼Œç¡®ä¿è´Ÿè½½å‡è¡¡</p>
</li>
<li>
<p>å†…å­˜è®¿é—®ä¼˜åŒ–ï¼š
  é‡‡ç”¨åˆ†å—ç­–ç•¥å‡å°‘cache missï¼š</p>
</li>
</ul>
<pre class="codehilite"><code>Block_size = sqrt(Cache_size / (3 Ã— d Ã— sizeof(float)))
</code></pre>

<p>å®é™…å¹¶è¡ŒåŒ–æ–¹æ¡ˆè®¾è®¡ï¼š</p>
<p>å¯¹äºå…¸å‹çš„ARMå¤§å°æ ¸æ¶æ„ï¼š</p>
<pre class="codehilite"><code># Cortex-A78 (4ä¸ªå¤§æ ¸) + Cortex-A55 (4ä¸ªå°æ ¸)
if (n &gt; 256):
    # é•¿åºåˆ—ï¼šå¤§æ ¸å¤„ç†è®¡ç®—å¯†é›†éƒ¨åˆ†
    assign_to_big_cores(attention_computation)
    assign_to_little_cores(memory_operations)
else:
    # çŸ­åºåˆ—ï¼šå…¨éƒ¨ä½¿ç”¨å¤§æ ¸
    assign_to_big_cores(all_operations)
</code></pre>

<p>å†…å­˜è®¿é—®æ¨¡å¼ä¼˜åŒ–ï¼š</p>
<pre class="codehilite"><code># 2Dåˆ†å—æ–¹æ¡ˆ
for i in range(0, n, block_i):
    for j in range(0, n, block_j):
        # å—å†…è®¡ç®—ï¼Œæœ€å¤§åŒ–æ•°æ®é‡ç”¨
        compute_attention_block(Q[i:i+block_i], 
                                K[j:j+block_j],
                                V[j:j+block_j])
</code></pre>

<p>æœ€ä½³å—å¤§å°é€‰æ‹©ï¼š</p>
<ul>
<li>L1 Cache (32KB): block_size = 32</li>
<li>L2 Cache (256KB): block_size = 96 </li>
<li>L3 Cache (2MB): block_size = 256</li>
</ul>
<ol start="2">
<li><strong>å¼ é‡å¹¶è¡Œï¼ˆTensor Parallelismï¼‰</strong></li>
</ol>
<p>å°†æ¨¡å‹æƒé‡æŒ‰ç»´åº¦åˆ‡åˆ†ï¼Œåˆ†å¸ƒåˆ°å¤šä¸ªè®¡ç®—å•å…ƒï¼š</p>
<ul>
<li>æ³¨æ„åŠ›å¤´å¹¶è¡Œï¼š</li>
</ul>
<pre class="codehilite"><code>Q_i = X Ã— W_q^i, i âˆˆ [1, h/P]
</code></pre>

<p>æ¯ä¸ªè®¾å¤‡è®¡ç®—h/Pä¸ªæ³¨æ„åŠ›å¤´</p>
<ul>
<li>FFNåˆ—å¹¶è¡Œï¼š</li>
</ul>
<pre class="codehilite"><code>FFN_up = X Ã— [W_up^1 | W_up^2 | ... | W_up^P]
</code></pre>

<p>å°†å‡ç»´çŸ©é˜µæŒ‰åˆ—åˆ‡åˆ†</p>
<ul>
<li>é€šä¿¡å¼€é”€ï¼š
  éœ€è¦åœ¨æ³¨æ„åŠ›è®¡ç®—åè¿›è¡Œall-reduceï¼š</li>
</ul>
<pre class="codehilite"><code>Comm_cost = 2 Ã— (P-1) Ã— n Ã— d Ã— sizeof(float) / Bandwidth
</code></pre>

<p>å¼ é‡å¹¶è¡Œçš„æ•ˆç‡åˆ†æï¼š</p>
<p>å¹¶è¡Œæ•ˆç‡å…¬å¼ï¼š</p>
<pre class="codehilite"><code>Efficiency_TP = Computation_time / (Computation_time + Communication_time)
              = 1 / (1 + Comm_cost / Comp_cost)
</code></pre>

<p>å¯¹äºä¸åŒçš„å¹¶è¡Œç­–ç•¥ï¼š</p>
<ol>
<li>
<p>æ³¨æ„åŠ›å¤´å¹¶è¡Œï¼ˆæ¨èï¼‰ï¼š
   - é€šä¿¡é‡ï¼šO(n Ã— d)
   - è®¡ç®—é‡ï¼šO(nÂ² Ã— d/P)
   - æ•ˆç‡ï¼šå½“n &gt; 64æ—¶é€šå¸¸ &gt; 90%</p>
</li>
<li>
<p>è¡Œå¹¶è¡Œï¼ˆä¸æ¨èï¼‰ï¼š
   - é€šä¿¡é‡ï¼šO(nÂ²)
   - è®¡ç®—é‡ï¼šO(nÂ² Ã— d/P)
   - æ•ˆç‡ï¼šç”±äºé€šä¿¡é‡å¤§ï¼Œé€šå¸¸ &lt; 70%</p>
</li>
<li>
<p>FFNå¹¶è¡Œï¼š
   - é€šä¿¡é‡ï¼šO(n Ã— d)
   - è®¡ç®—é‡ï¼šO(n Ã— dÂ²/P)
   - æ•ˆç‡ï¼šé€šå¸¸ &gt; 85%</p>
</li>
</ol>
<p>å®é™…åº”ç”¨ä¸­çš„æƒè¡¡ï¼š</p>
<pre class="codehilite"><code>if (available_bandwidth &gt; 10 GB/s):
    use_tensor_parallelism()  # é«˜å¸¦å®½ç¯å¢ƒ
else:
    use_data_parallelism()    # ä½å¸¦å®½ç¯å¢ƒ
</code></pre>

<ol start="3">
<li><strong>æµæ°´çº¿å¹¶è¡Œä¼˜åŒ–</strong></li>
</ol>
<p>å¯¹äºè¾¹ç¼˜è®¾å¤‡ï¼Œå¯ä»¥è®¾è®¡è½»é‡çº§æµæ°´çº¿ï¼š</p>
<ul>
<li>å±‚é—´æµæ°´çº¿ï¼š</li>
</ul>
<pre class="codehilite"><code>Layer_iå¤„ç†Token[0:k]æ—¶ï¼ŒLayer_(i-1)å¤„ç†Token[k:2k]
</code></pre>

<ul>
<li>å¾®æ‰¹å¤„ç†ç­–ç•¥ï¼š
  å°†åºåˆ—åˆ†ä¸ºmä¸ªå¾®æ‰¹ï¼Œæµæ°´çº¿æ·±åº¦ä¸ºLï¼š</li>
</ul>
<pre class="codehilite"><code>Pipeline_efficiency = m / (m + L - 1)
</code></pre>

<p>æµæ°´çº¿è°ƒåº¦ç®—æ³•ï¼š</p>
<p>1F1Bï¼ˆOne Forward One Backwardï¼‰ç­–ç•¥é€‚é…ï¼š</p>
<pre class="codehilite"><code># é¢„å¡«å……é˜¶æ®µåªæœ‰å‰å‘ä¼ æ’­
for stage in range(num_stages):
    for micro_batch in range(num_micro_batches):
        if is_ready(stage, micro_batch):
            forward(stage, micro_batch)
            send_to_next_stage(stage, micro_batch)
</code></pre>

<p>æ³¡æ²«ï¼ˆBubbleï¼‰ä¼˜åŒ–ï¼š</p>
<pre class="codehilite"><code>Bubble_ratio = (L - 1) / (m + L - 1)

# å‡å°‘æ³¡æ²«çš„ç­–ç•¥

1. å¢åŠ å¾®æ‰¹æ•°é‡ m
2. å‡å°‘æµæ°´çº¿æ·±åº¦ Lï¼ˆé€šè¿‡å±‚åˆå¹¶ï¼‰
3. ä½¿ç”¨äº¤é”™è°ƒåº¦ï¼ˆInterleaved Scheduleï¼‰
</code></pre>

<p>å®é™…æµæ°´çº¿è®¾è®¡ç¤ºä¾‹ï¼š</p>
<pre class="codehilite"><code># 32å±‚æ¨¡å‹ï¼Œ4ä¸ªè®¡ç®—å•å…ƒ
Stage 0: Layer[0:8]
Stage 1: Layer[8:16]  
Stage 2: Layer[16:24]
Stage 3: Layer[24:32]

# è´Ÿè½½å‡è¡¡è€ƒè™‘
if (layer.is_attention()):
    weight = 1.5  # Attentionå±‚æ›´é‡
else:
    weight = 1.0  # FFNå±‚
</code></pre>

<ol start="4">
<li><strong>å¼‚æ„è®¡ç®—åˆ©ç”¨</strong></li>
</ol>
<p>å……åˆ†åˆ©ç”¨è¾¹ç¼˜è®¾å¤‡çš„å¼‚æ„æ¶æ„ï¼š</p>
<ul>
<li>CPUè´Ÿè´£ï¼šè½»é‡çº§é¢„å¤„ç†ã€æ§åˆ¶æµ</li>
<li>GPU/NPUè´Ÿè´£ï¼šçŸ©é˜µå¯†é›†è®¡ç®—</li>
<li>DSPè´Ÿè´£ï¼šç‰¹å®šç®—å­åŠ é€Ÿï¼ˆå¦‚Softmaxï¼‰</li>
</ul>
<p>ä»»åŠ¡åˆ†é…ç­–ç•¥ï¼š</p>
<pre class="codehilite"><code>if (Compute_intensity &gt; Threshold_GPU):
    assign_to_GPU()
elif (is_special_op()):
    assign_to_DSP()
else:
    assign_to_CPU()
</code></pre>

<p>å…·ä½“çš„å¼‚æ„ååŒæ–¹æ¡ˆï¼š</p>
<ol>
<li>Qualcomm Snapdragonå¹³å°ï¼š</li>
</ol>
<pre class="codehilite"><code># CPU (Kryo): æ§åˆ¶æµ + Tokenization
# GPU (Adreno): çŸ©é˜µä¹˜æ³•
# DSP (Hexagon): Softmax + LayerNorm
# NPU: INT8æ¨ç†åŠ é€Ÿ

ä»»åŠ¡åˆ’åˆ†ï¼š
CPU: tokenize() -&gt; embedding_lookup()
GPU: attention_compute() -&gt; ffn_compute()  
DSP: softmax() -&gt; layer_norm()
NPU: quantized_inference() å½“å¯ç”¨INT8æ—¶
</code></pre>

<ol start="2">
<li>Apple Siliconå¹³å°ï¼š</li>
</ol>
<pre class="codehilite"><code># CPU (Performance/Efficiency cores): å‰å¤„ç†
# GPU: ä¸»è¦è®¡ç®—
# Neural Engine: ç‰¹å®šç®—å­åŠ é€Ÿ

ç»Ÿä¸€å†…å­˜ä¼˜åŠ¿ï¼š

- é›¶æ‹·è´æ•°æ®ä¼ è¾“
- åŠ¨æ€å·¥ä½œè´Ÿè½½è¿ç§»
- ç»†ç²’åº¦ååŒ
</code></pre>

<ol start="3">
<li>è´Ÿè½½æ„ŸçŸ¥çš„åŠ¨æ€è°ƒåº¦ï¼š</li>
</ol>
<pre class="codehilite"><code>class HeterogeneousScheduler:
    def schedule(self, op, input_size):
        # è®¡ç®—é¢„æœŸå»¶è¿Ÿ
        cpu_latency = estimate_cpu_latency(op, input_size)
        gpu_latency = estimate_gpu_latency(op, input_size)
        dsp_latency = estimate_dsp_latency(op, input_size)

        # è€ƒè™‘å½“å‰è´Ÿè½½
        cpu_latency *= (1 + cpu_load)
        gpu_latency *= (1 + gpu_load)
        dsp_latency *= (1 + dsp_load)

        # é€‰æ‹©æœ€ä¼˜è®¾å¤‡
        return argmin([cpu_latency, gpu_latency, dsp_latency])
</code></pre>

<ol start="4">
<li>èƒ½æ•ˆæƒè¡¡ï¼š</li>
</ol>
<pre class="codehilite"><code># æ¯ä¸ªè®¾å¤‡çš„èƒ½æ•ˆæ¯”ï¼ˆGFLOPS/Wï¼‰
Energy_efficiency = {
    &quot;CPU&quot;: 5,
    &quot;GPU&quot;: 15,
    &quot;DSP&quot;: 25,
    &quot;NPU&quot;: 50
}

# ç”µæ± ä¼˜å…ˆæ¨¡å¼
if (battery_mode):
    prefer_device(&quot;NPU&quot; if supports_op else &quot;DSP&quot;)
else:
    prefer_device(&quot;GPU&quot;)  # æ€§èƒ½ä¼˜å…ˆ
</code></pre>

<h3 id="1622">16.2.2 ç®—å­èåˆæŠ€æœ¯</h3>
<p>ç®—å­èåˆé€šè¿‡å‡å°‘å†…å­˜è®¿é—®æ¬¡æ•°å’Œkernelå¯åŠ¨å¼€é”€æ¥æå‡æ€§èƒ½ã€‚</p>
<ol>
<li><strong>Attentionç®—å­èåˆ</strong></li>
</ol>
<p>ä¼ ç»Ÿå®ç°éœ€è¦å¤šæ¬¡å†…å­˜è¯»å†™ï¼š</p>
<pre class="codehilite"><code>Q = X @ W_q  # è¯»Xï¼Œå†™Q
K = X @ W_k  # è¯»Xï¼Œå†™K  
V = X @ W_v  # è¯»Xï¼Œå†™V
S = Q @ K^T  # è¯»Qã€Kï¼Œå†™S
P = Softmax(S)  # è¯»Sï¼Œå†™P
O = P @ V    # è¯»Pã€Vï¼Œå†™O
</code></pre>

<p>èåˆåçš„Flash Attentioné£æ ¼å®ç°ï¼š</p>
<pre class="codehilite"><code>for block_q in Q_blocks:
    for block_k, block_v in zip(K_blocks, V_blocks):
        block_s = block_q @ block_k^T
        block_p = softmax(block_s)
        block_o += block_p @ block_v
</code></pre>

<p>å†…å­˜è®¿é—®å‡å°‘ï¼š</p>
<pre class="codehilite"><code>Memory_reduction = 1 - (2Ã—sqrt(n) + d) / (2Ã—n + 4Ã—d)
</code></pre>

<p>è¯¦ç»†çš„Flash Attentionä¼˜åŒ–åˆ†æï¼š</p>
<p>å†…å­˜è®¿é—®å¯¹æ¯”ï¼š</p>
<pre class="codehilite"><code>ä¼ ç»Ÿæ–¹æ³•ï¼š

- è¯»ï¼š3nd + 2nÂ² + 2nd = O(nÂ² + nd)
- å†™ï¼š3nd + nÂ² + nd = O(nÂ² + nd)
- æ€»è®¡ï¼šO(nÂ² + nd)

Flash Attentionï¼š

- è¯»ï¼šO(nd + nÂ²/M)ï¼Œå…¶ä¸­Mä¸ºå—å¤§å°
- å†™ï¼šO(nd)
- æ€»è®¡ï¼šO(nd + nÂ²/M)
</code></pre>

<p>å½“M = âˆšnæ—¶ï¼Œå†…å­˜è®¿é—®ä»O(nÂ²)é™ä½åˆ°O(nâˆšn)ã€‚</p>
<p>å—å¤§å°é€‰æ‹©ç­–ç•¥ï¼š</p>
<pre class="codehilite"><code># åŸºäºSRAMå¤§å°é€‰æ‹©
SRAM_size = 96KB  # GPUç‰‡ä¸ŠSRAM
Elements_per_block = SRAM_size / (3 Ã— sizeof(fp16))
Block_size = sqrt(Elements_per_block)

# å…¸å‹å€¼ï¼š
if (GPU_type == &quot;A100&quot;):
    block_size = 128
elif (GPU_type == &quot;V100&quot;):
    block_size = 64
elif (GPU_type == &quot;Mobile&quot;):
    block_size = 32
</code></pre>

<p>æ³¨æ„åŠ›èåˆçš„å˜ä½“ï¼š</p>
<ol>
<li>Flash Attention v2ï¼ˆæ”¯æŒä¸è§„åˆ™æ©ç ï¼‰ï¼š</li>
</ol>
<pre class="codehilite"><code>for block_q in Q_blocks:
    for block_k, block_v in zip(K_blocks, V_blocks):
        block_mask = mask[block_q_idx, block_k_idx]
        if not is_all_masked(block_mask):
            block_s = block_q @ block_k^T + block_mask
            block_p = softmax(block_s)
            block_o += block_p @ block_v
</code></pre>

<ol start="2">
<li>Multi-Query Attentionèåˆï¼š</li>
</ol>
<pre class="codehilite"><code># K, Vå…±äº«ï¼Œå‡å°‘å†…å­˜è®¿é—®
for block_q in Q_blocks:
    for block_kv in KV_blocks:  # Kå’ŒVåˆå¹¶
        block_s = block_q @ block_kv.K^T
        block_p = softmax(block_s)
        block_o += block_p @ block_kv.V
</code></pre>

<ol start="2">
<li><strong>LayerNorm-Linearèåˆ</strong></li>
</ol>
<p>å°†LayerNormä¸åç»­Linearå±‚èåˆï¼š</p>
<p>åŸå§‹è®¡ç®—ï¼š</p>
<pre class="codehilite"><code>Y_norm = LayerNorm(X)  # éœ€è¦è¯»å†™ä¸­é—´ç»“æœ
Y = Y_norm @ W + b
</code></pre>

<p>èåˆè®¡ç®—ï¼š</p>
<pre class="codehilite"><code>mean = reduce_mean(X)
var = reduce_var(X)
Y = ((X - mean) / sqrt(var + Îµ)) @ W + b
</code></pre>

<p>èŠ‚çœçš„å†…å­˜è®¿é—®ï¼šn Ã— d Ã— sizeof(float)</p>
<ol start="3">
<li><strong>æ¿€æ´»å‡½æ•°èåˆ</strong></li>
</ol>
<p>å°†GELU/SiLUç­‰æ¿€æ´»å‡½æ•°ä¸å‰åæ“ä½œèåˆï¼š</p>
<pre class="codehilite"><code># åŸå§‹
H1 = X @ W1
H2 = GELU(H1)
Y = H2 @ W2

# èåˆ
Y = GELU_Linear_fusion(X, W1, W2)
</code></pre>

<ol start="4">
<li><strong>é‡åŒ–-åé‡åŒ–èåˆ</strong></li>
</ol>
<p>å¯¹äºINT8æ¨ç†ï¼Œèåˆé‡åŒ–æ“ä½œï¼š</p>
<pre class="codehilite"><code># åŸå§‹
X_int8 = quantize(X_fp16)
Y_int8 = X_int8 @ W_int8
Y_fp16 = dequantize(Y_int8)

# èåˆ
Y_fp16 = fused_int8_gemm(X_fp16, W_int8, scale_x, scale_w)
</code></pre>

<h3 id="1623">16.2.3 å†…å­˜è®¿é—®æ¨¡å¼ä¼˜åŒ–</h3>
<p>å†…å­˜è®¿é—®æ˜¯è¾¹ç¼˜è®¾å¤‡çš„ä¸»è¦ç“¶é¢ˆï¼Œä¼˜åŒ–è®¿é—®æ¨¡å¼è‡³å…³é‡è¦ã€‚</p>
<ol>
<li><strong>æ•°æ®å¸ƒå±€ä¼˜åŒ–</strong></li>
</ol>
<p>é€‰æ‹©åˆé€‚çš„æ•°æ®å¸ƒå±€ä»¥æé«˜cacheå‘½ä¸­ç‡ï¼š</p>
<ul>
<li>åºåˆ—ä¼˜å…ˆï¼ˆSequence-firstï¼‰ï¼š</li>
</ul>
<pre class="codehilite"><code>Layout: [seq_len, batch, hidden_dim]
</code></pre>

<p>é€‚åˆattentionè®¡ç®—</p>
<ul>
<li>æ‰¹ä¼˜å…ˆï¼ˆBatch-firstï¼‰ï¼š</li>
</ul>
<pre class="codehilite"><code>Layout: [batch, seq_len, hidden_dim]
</code></pre>

<p>é€‚åˆFFNè®¡ç®—</p>
<ul>
<li>åŠ¨æ€è½¬ç½®ç­–ç•¥ï¼š
  æ ¹æ®åç»­æ“ä½œé€‰æ‹©æ˜¯å¦è½¬ç½®</li>
</ul>
<p>æ•°æ®å¸ƒå±€é€‰æ‹©çš„å®šé‡åˆ†æï¼š</p>
<p>è®¿é—®æ¨¡å¼åˆ†æï¼š</p>
<pre class="codehilite"><code>Attentionè®¡ç®—ï¼š

- QÃ—K^T: [seq, batch, head, dim] Ã— [seq, batch, head, dim]^T
- åºåˆ—ä¼˜å…ˆå¸ƒå±€ï¼šè¿ç»­è®¿é—®ï¼Œcacheå‹å¥½
- æ‰¹ä¼˜å…ˆå¸ƒå±€ï¼šè·¨æ­¥è®¿é—®ï¼Œcache missé«˜

FFNè®¡ç®—ï¼š

- XÃ—W: [batch, seq, dim] Ã— [dim, ffn_dim]
- æ‰¹ä¼˜å…ˆå¸ƒå±€ï¼šåˆ©äºGEMMä¼˜åŒ–
- åºåˆ—ä¼˜å…ˆå¸ƒå±€ï¼šéœ€è¦è½¬ç½®
</code></pre>

<p>æ··åˆå¸ƒå±€ç­–ç•¥ï¼š</p>
<pre class="codehilite"><code>class AdaptiveLayout:
    def __init__(self):
        self.transpose_cost = measure_transpose_cost()

    def choose_layout(self, current_op, next_op):
        if is_attention(current_op) and is_attention(next_op):
            return &quot;seq_first&quot;
        elif is_ffn(current_op) and is_ffn(next_op):
            return &quot;batch_first&quot;
        else:
            # è®¡ç®—è½¬ç½®æˆæœ¬
            benefit = compute_benefit(next_op)
            if benefit &gt; self.transpose_cost:
                return &quot;transpose&quot;
            return &quot;keep_current&quot;
</code></pre>

<p>å†…å­˜å¯¹é½ä¼˜åŒ–ï¼š</p>
<pre class="codehilite"><code># å¯¹é½åˆ°ç¼“å­˜è¡Œå¤§å°ï¼ˆ64å­—èŠ‚ï¼‰
aligned_dim = ((hidden_dim * sizeof(fp16) + 63) // 64) * 64 / sizeof(fp16)

# SIMDå¯¹é½ï¼ˆARM NEONä¸º128ä½ï¼‰
simd_aligned_dim = ((hidden_dim + 7) // 8) * 8
</code></pre>

<ol start="2">
<li><strong>é¢„å–ï¼ˆPrefetchingï¼‰ç­–ç•¥</strong></li>
</ol>
<p>åˆ©ç”¨ç¡¬ä»¶é¢„å–æœºåˆ¶ï¼š</p>
<pre class="codehilite"><code>for i in range(0, n, block_size):
    prefetch(W[i+block_size:i+2*block_size])
    compute(X[i:i+block_size], W[i:i+block_size])
</code></pre>

<p>ä¸åŒçº§åˆ«çš„é¢„å–ç­–ç•¥ï¼š</p>
<ol>
<li>ç¡¬ä»¶é¢„å–ï¼š</li>
</ol>
<pre class="codehilite"><code># ARMå¹³å°
PLDW [address, #offset]  # é¢„å–åˆ°L2 cache
PRFM PLDL1KEEP, [address, #offset]  # é¢„å–åˆ°L1 cache

# x86å¹³å°  
_mm_prefetch(address, _MM_HINT_T0)  # é¢„å–åˆ°æ‰€æœ‰cacheçº§åˆ«
_mm_prefetch(address, _MM_HINT_T1)  # é¢„å–åˆ°L2åŠä»¥ä¸Š
</code></pre>

<ol start="2">
<li>è½¯ä»¶é¢„å–è·ç¦»è®¡ç®—ï¼š</li>
</ol>
<pre class="codehilite"><code>prefetch_distance = compute_latency / memory_latency
                  = (FLOPs_per_iteration / Peak_FLOPS) / 
                    (Bytes_per_iteration / Bandwidth)

# å®ä¾‹ï¼šçŸ©é˜µä¹˜æ³•
FLOPs_per_iter = 2 * block_size^3
Bytes_per_iter = 3 * block_size^2 * sizeof(fp16)
prefetch_distance = (2 * block_size) / (3 * sizeof(fp16) * Peak_FLOPS/Bandwidth)
</code></pre>

<ol start="3">
<li>è‡ªé€‚åº”é¢„å–ï¼š</li>
</ol>
<pre class="codehilite"><code>class AdaptivePrefetcher:
    def __init__(self):
        self.hit_rate = 0.9
        self.distance = 2

    def prefetch(self, address, stride):
        # ç›‘æµ‹å‘½ä¸­ç‡
        if self.hit_rate &lt; 0.8:
            self.distance += 1  # å¢åŠ é¢„å–è·ç¦»
        elif self.hit_rate &gt; 0.95:
            self.distance -= 1  # å‡å°‘é¢„å–è·ç¦»

        # å‘å‡ºé¢„å–
        for i in range(self.distance):
            prefetch(address + i * stride)
</code></pre>

<ol start="3">
<li><strong>å†…å­˜æ± ç®¡ç†</strong></li>
</ol>
<p>é¿å…é¢‘ç¹çš„å†…å­˜åˆ†é…ï¼š</p>
<ul>
<li>é¢„åˆ†é…æ¿€æ´»å€¼ç¼“å†²åŒº</li>
<li>å¾ªç¯ä½¿ç”¨ä¸´æ—¶buffer</li>
<li>é‡‡ç”¨ring bufferç®¡ç†KV Cache</li>
</ul>
<p>å†…å­˜æ± å¤§å°ä¼°ç®—ï¼š</p>
<pre class="codehilite"><code>Pool_size = max_batch Ã— max_seq_len Ã— d Ã— L Ã— 2 Ã— sizeof(float)
</code></pre>

<p>é«˜æ•ˆçš„å†…å­˜æ± è®¾è®¡ï¼š</p>
<ol>
<li>åˆ†çº§å†…å­˜æ± ï¼š</li>
</ol>
<pre class="codehilite"><code>class HierarchicalMemoryPool:
    def __init__(self):
        self.pools = {
            &quot;small&quot;: Pool(size=1MB, block=4KB),    # å°å¯¹è±¡
            &quot;medium&quot;: Pool(size=16MB, block=64KB),  # ä¸­ç­‰å¯¹è±¡
            &quot;large&quot;: Pool(size=256MB, block=1MB),   # å¤§å¯¹è±¡
            &quot;huge&quot;: Pool(size=2GB, block=16MB)      # KV Cache
        }

    def allocate(self, size):
        if size &lt; 4KB:
            return self.pools[&quot;small&quot;].alloc()
        elif size &lt; 64KB:
            return self.pools[&quot;medium&quot;].alloc()
        elif size &lt; 1MB:
            return self.pools[&quot;large&quot;].alloc()
        else:
            return self.pools[&quot;huge&quot;].alloc()
</code></pre>

<ol start="2">
<li>é›¶æ‹·è´å†…å­˜å…±äº«ï¼š</li>
</ol>
<pre class="codehilite"><code>class ZeroCopyBuffer:
    def __init__(self, size):
        # ä½¿ç”¨mmapåˆ›å»ºå…±äº«å†…å­˜
        self.shm = mmap.mmap(-1, size)
        self.views = {}  # ä¸åŒè§†å›¾

    def create_view(self, offset, shape, dtype):
        # åˆ›å»ºä¸åŒç±»å‹çš„è§†å›¾ï¼Œæ— éœ€æ‹·è´
        return np.frombuffer(self.shm, dtype=dtype, 
                            count=np.prod(shape),
                            offset=offset).reshape(shape)
</code></pre>

<ol start="3">
<li>å†…å­˜å¤ç”¨ç­–ç•¥ï¼š</li>
</ol>
<pre class="codehilite"><code># æ¿€æ´»å€¼å†…å­˜å¤ç”¨
activation_memory = allocate(max_activation_size)

for layer in layers:
    # è¾“å…¥å’Œè¾“å‡ºäº¤æ›¿ä½¿ç”¨åŒä¸€å—å†…å­˜
    if layer_id % 2 == 0:
        input_buf = activation_memory[0:half]
        output_buf = activation_memory[half:]
    else:
        input_buf = activation_memory[half:]
        output_buf = activation_memory[0:half]

    layer.forward(input_buf, output_buf)
</code></pre>

<ol start="4">
<li>å†…å­˜ç¢ç‰‡ç®¡ç†ï¼š</li>
</ol>
<pre class="codehilite"><code>class DefragmentingPool:
    def periodic_defrag(self):
        if fragmentation_ratio &gt; 0.3:
            # åˆå¹¶ç›¸é‚»ç©ºé—²å—
            self.merge_free_blocks()
            # ç§»åŠ¨åˆ†é…å—ä»¥åˆ›å»ºè¿ç»­ç©ºé—´
            self.compact_allocated_blocks()
</code></pre>

<ol start="4">
<li><strong>NUMAæ„ŸçŸ¥ä¼˜åŒ–</strong></li>
</ol>
<p>å¯¹äºå¤šæ ¸è¾¹ç¼˜å¤„ç†å™¨ï¼š</p>
<ul>
<li>å°†æ•°æ®ç»‘å®šåˆ°è®¡ç®—æ ¸å¿ƒé™„è¿‘</li>
<li>æœ€å°åŒ–è·¨NUMAèŠ‚ç‚¹è®¿é—®</li>
<li>é‡‡ç”¨æœ¬åœ°è®¡ç®—-å…¨å±€å½’çº¦æ¨¡å¼</li>
</ul>
<p>NUMAä¼˜åŒ–å®ç°ï¼š</p>
<ol>
<li>äº²å’Œæ€§è®¾ç½®ï¼š</li>
</ol>
<pre class="codehilite"><code># Linux NUMA API
def setup_numa_affinity(thread_id, data_ptr):
    # è·å–çº¿ç¨‹æ‰€åœ¨NUMAèŠ‚ç‚¹
    numa_node = numa_node_of_cpu(thread_id)

    # å°†æ•°æ®è¿ç§»åˆ°åŒä¸€èŠ‚ç‚¹
    numa_migrate_pages(data_ptr, numa_node)

    # ç»‘å®šCPUäº²å’Œæ€§
    cpu_set = numa_node_to_cpus(numa_node)
    sched_setaffinity(thread_id, cpu_set)
</code></pre>

<ol start="2">
<li>æ•°æ®åˆ†å¸ƒç­–ç•¥ï¼š</li>
</ol>
<pre class="codehilite"><code>class NumaAwareDistribution:
    def distribute_data(self, tensor, num_nodes):
        chunk_size = tensor.size // num_nodes
        distributions = []

        for node in range(num_nodes):
            start = node * chunk_size
            end = start + chunk_size

            # åœ¨æŒ‡å®šNUMAèŠ‚ç‚¹åˆ†é…
            chunk = numa_alloc_onnode(chunk_size, node)
            chunk.copy_from(tensor[start:end])
            distributions.append((node, chunk))

        return distributions
</code></pre>

<ol start="3">
<li>è·¨èŠ‚ç‚¹é€šä¿¡ä¼˜åŒ–ï¼š</li>
</ol>
<pre class="codehilite"><code># æœ€å°åŒ–è·¨èŠ‚ç‚¹é€šä¿¡
class NumaAwareReducer:
    def reduce(self, partials):
        # ç¬¬ä¸€é˜¶æ®µï¼šèŠ‚ç‚¹å†…å½’çº¦
        node_results = []
        for node in numa_nodes:
            local_partials = [p for n, p in partials if n == node]
            node_result = reduce_local(local_partials)
            node_results.append(node_result)

        # ç¬¬äºŒé˜¶æ®µï¼šè·¨èŠ‚ç‚¹å½’çº¦ï¼ˆæœ€å°åŒ–ï¼‰
        final_result = reduce_across_nodes(node_results)
        return final_result
</code></pre>

<ol start="4">
<li>å®é™…æ€§èƒ½å½±å“ï¼š</li>
</ol>
<pre class="codehilite"><code># æµ‹é‡æ•°æ®ï¼ˆåŒè·¯CPUç³»ç»Ÿï¼‰
æœ¬åœ°å†…å­˜è®¿é—®å»¶è¿Ÿï¼š~100ns
è¿œç¨‹å†…å­˜è®¿é—®å»¶è¿Ÿï¼š~150ns
NUMAä¼˜åŒ–æ”¶ç›Šï¼š20-40%æ€§èƒ½æå‡
</code></pre>

<h3 id="1624">16.2.4 åŠ¨æ€å½¢çŠ¶ä¼˜åŒ–</h3>
<p>è¾¹ç¼˜æ¨ç†é¢ä¸´å˜é•¿è¾“å…¥çš„æŒ‘æˆ˜ï¼Œéœ€è¦åŠ¨æ€é€‚é…ã€‚</p>
<ol>
<li><strong>Paddingç­–ç•¥ä¼˜åŒ–</strong></li>
</ol>
<p>æ™ºèƒ½paddingå‡å°‘æ— æ•ˆè®¡ç®—ï¼š</p>
<pre class="codehilite"><code># æ¡¶åŒ–ç­–ç•¥
buckets = [64, 128, 256, 512, 1024]
padded_len = min(b for b in buckets if b &gt;= actual_len)
</code></pre>

<p>paddingå¼€é”€åˆ†æï¼š</p>
<pre class="codehilite"><code>Overhead = (padded_len - actual_len) / padded_len
</code></pre>

<ol start="2">
<li><strong>åŠ¨æ€æ‰¹å¤„ç†</strong></li>
</ol>
<p>æ ¹æ®å®é™…é•¿åº¦åŠ¨æ€ç»„æ‰¹ï¼š</p>
<pre class="codehilite"><code>def dynamic_batching(requests, max_tokens):
    batch = []
    current_tokens = 0
    for req in sorted(requests, key=lambda x: x.length):
        if current_tokens + req.length &lt;= max_tokens:
            batch.append(req)
            current_tokens += req.length
        else:
            yield batch
            batch = [req]
            current_tokens = req.length
</code></pre>

<ol start="3">
<li><strong>åˆ†å—æ³¨æ„åŠ›è®¡ç®—</strong></li>
</ol>
<p>å¯¹äºè¶…é•¿åºåˆ—ï¼Œé‡‡ç”¨åˆ†å—ç­–ç•¥ï¼š</p>
<pre class="codehilite"><code>chunk_size = sqrt(available_memory / (3 Ã— d Ã— sizeof(float)))
for i in range(0, n, chunk_size):
    for j in range(0, n, chunk_size):
        compute_attention_block(Q[i:i+chunk_size], 
                                K[j:j+chunk_size],
                                V[j:j+chunk_size])
</code></pre>

<ol start="4">
<li><strong>JITç¼–è¯‘ä¼˜åŒ–</strong></li>
</ol>
<p>é’ˆå¯¹ç‰¹å®šå½¢çŠ¶ç”Ÿæˆä¼˜åŒ–ä»£ç ï¼š</p>
<ul>
<li>åˆ©ç”¨TensorRTçš„å½¢çŠ¶ç‰¹åŒ–</li>
<li>ä½¿ç”¨XLAçš„å½¢çŠ¶æ¨æ–­</li>
<li>ç¼“å­˜ç¼–è¯‘ç»“æœé¿å…é‡å¤ç¼–è¯‘</li>
</ul>
<p>ç¼–è¯‘ç¼“å­˜å‘½ä¸­ç‡ï¼š</p>
<pre class="codehilite"><code>Hit_rate = cached_shapes / total_shapes
</code></pre>

<p>ä¼˜åŒ–ç›®æ ‡æ˜¯æé«˜å¸¸è§å½¢çŠ¶çš„å‘½ä¸­ç‡ã€‚</p>
<h2 id="163">16.3 æ··åˆç²¾åº¦é¢„å¡«å……ç­–ç•¥</h2>
<p>æ··åˆç²¾åº¦æŠ€æœ¯é€šè¿‡åœ¨ä¸åŒè®¡ç®—é˜¶æ®µä½¿ç”¨ä¸åŒæ•°å€¼ç²¾åº¦ï¼Œåœ¨ä¿æŒæ¨¡å‹è´¨é‡çš„åŒæ—¶æ˜¾è‘—æå‡æ¨ç†é€Ÿåº¦ã€‚é¢„å¡«å……é˜¶æ®µçš„æ··åˆç²¾åº¦ä¼˜åŒ–éœ€è¦ä»”ç»†æƒè¡¡ç²¾åº¦æŸå¤±ä¸æ€§èƒ½æå‡ã€‚</p>
<h3 id="1631">16.3.1 é¢„å¡«å……é˜¶æ®µçš„ç²¾åº¦éœ€æ±‚åˆ†æ</h3>
<p>ç†è§£ä¸åŒæ“ä½œå¯¹æ•°å€¼ç²¾åº¦çš„æ•æ„Ÿåº¦æ˜¯è®¾è®¡æ··åˆç²¾åº¦ç­–ç•¥çš„åŸºç¡€ã€‚</p>
<ol>
<li><strong>ç²¾åº¦æ•æ„Ÿåº¦çš„ç†è®ºåˆ†æ</strong></li>
</ol>
<p>å¯¹äºTransformerçš„å„ä¸ªç»„ä»¶ï¼Œç²¾åº¦éœ€æ±‚å·®å¼‚æ˜¾è‘—ï¼š</p>
<ul>
<li>çŸ©é˜µä¹˜æ³•çš„è¯¯å·®ä¼ æ’­ï¼š
  å¯¹äºC = A Ã— Bï¼Œä½¿ç”¨ä½ç²¾åº¦æ—¶çš„è¯¯å·®ä¸Šç•Œï¼š</li>
</ul>
<pre class="codehilite"><code>||C_low - C_high||_F â‰¤ ||A||_F Ã— ||B||_F Ã— Îµ_rel
</code></pre>

<p>å…¶ä¸­Îµ_relä¸ºç›¸å¯¹ç²¾åº¦è¯¯å·®</p>
<ul>
<li>Softmaxçš„æ•°å€¼ç¨³å®šæ€§ï¼š</li>
</ul>
<pre class="codehilite"><code>Softmax(x_i) = exp(x_i - max(x)) / Î£_j exp(x_j - max(x))
</code></pre>

<p>éœ€è¦é«˜ç²¾åº¦é¿å…æ•°å€¼æº¢å‡º</p>
<ul>
<li>LayerNormçš„ç²¾åº¦éœ€æ±‚ï¼š
  å‡å€¼å’Œæ–¹å·®è®¡ç®—éœ€è¦è¶³å¤Ÿç²¾åº¦é¿å…ç´¯ç§¯è¯¯å·®</li>
</ul>
<ol start="2">
<li><strong>å®è¯åˆ†æç»“æœ</strong></li>
</ol>
<p>åŸºäºå¤§é‡å®éªŒï¼Œä¸åŒæ“ä½œçš„ç²¾åº¦å®¹å¿åº¦æ’åºï¼š</p>
<pre class="codehilite"><code>å®¹å¿åº¦é«˜ â†’ ä½ï¼š
FFNå±‚ &gt; QKVæŠ•å½± &gt; æ³¨æ„åŠ›çŸ©é˜µä¹˜æ³• &gt; Softmax &gt; LayerNorm
</code></pre>

<p>å…·ä½“æ•°å€¼ï¼ˆä»¥perplexityå¢åŠ ç™¾åˆ†æ¯”è¡¡é‡ï¼‰ï¼š</p>
<ul>
<li>FFNå±‚ä½¿ç”¨INT8ï¼š+0.1%</li>
<li>æ³¨æ„åŠ›ä½¿ç”¨FP16ï¼š+0.05%</li>
<li>Softmaxä½¿ç”¨FP32ï¼šåŸºå‡†</li>
<li>å…¨éƒ¨FP16ï¼š+0.2%</li>
<li>æ··åˆç­–ç•¥ï¼š+0.08%</li>
</ul>
<ol start="3">
<li><strong>é¢„å¡«å……vsç”Ÿæˆçš„ç²¾åº¦éœ€æ±‚å·®å¼‚</strong></li>
</ol>
<p>é¢„å¡«å……é˜¶æ®µçš„ç‰¹ç‚¹ä½¿å…¶æ›´é€‚åˆæ¿€è¿›çš„é‡åŒ–ï¼š</p>
<ul>
<li>æ— ç´¯ç§¯è¯¯å·®ï¼šæ¯ä¸ªtokenç‹¬ç«‹è®¡ç®—</li>
<li>å¹¶è¡Œè®¡ç®—ï¼šå¯ä»¥ä½¿ç”¨æ›´å®½çš„æ•°æ®ç±»å‹</li>
<li>ä¸€æ¬¡æ€§è®¡ç®—ï¼šä¸éœ€è¦ç»´æŠ¤æ•°å€¼ç¨³å®šæ€§</li>
</ul>
<p>æ•°å­¦å»ºæ¨¡ï¼š</p>
<pre class="codehilite"><code>Error_prefill = Îµ Ã— n  # çº¿æ€§å¢é•¿
Error_generation = Îµ Ã— t^2  # äºŒæ¬¡å¢é•¿ï¼ˆè‡ªå›å½’ï¼‰
</code></pre>

<ol start="4">
<li><strong>ç¡¬ä»¶æ”¯æŒçš„ç²¾åº¦ç±»å‹</strong></li>
</ol>
<p>è¾¹ç¼˜ç¡¬ä»¶çš„ç²¾åº¦æ”¯æŒæƒ…å†µï¼š</p>
<ul>
<li>ARM Cortex-A78ï¼šFP32/FP16/INT8/INT4</li>
<li>Qualcomm Hexagonï¼šFP16/INT8/INT4</li>
<li>Mali G78 GPUï¼šFP32/FP16</li>
<li>Apple Neural Engineï¼šFP16/INT8</li>
</ul>
<p>é€‰æ‹©ç­–ç•¥ï¼š</p>
<pre class="codehilite"><code>Precision = argmax(Hardware_throughput(p) / Quality_loss(p))
</code></pre>

<h3 id="1632">16.3.2 å±‚çº§æ··åˆç²¾åº¦è®¾è®¡</h3>
<p>åŸºäºç²¾åº¦éœ€æ±‚åˆ†æï¼Œè®¾è®¡åˆ†å±‚çš„æ··åˆç²¾åº¦æ–¹æ¡ˆã€‚</p>
<ol>
<li><strong>é™æ€æ··åˆç²¾åº¦é…ç½®</strong></li>
</ol>
<p>é¢„å®šä¹‰æ¯å±‚çš„ç²¾åº¦é…ç½®ï¼š</p>
<pre class="codehilite"><code>Layer_config = {
    &quot;embedding&quot;: FP16,
    &quot;attention&quot;: {
        &quot;qkv_proj&quot;: INT8,
        &quot;attn_scores&quot;: FP16,
        &quot;softmax&quot;: FP32,
        &quot;out_proj&quot;: INT8
    },
    &quot;ffn&quot;: {
        &quot;up_proj&quot;: INT8,
        &quot;activation&quot;: FP16,
        &quot;down_proj&quot;: INT8
    },
    &quot;layer_norm&quot;: FP32
}
</code></pre>

<ol start="2">
<li><strong>æ¸è¿›å¼ç²¾åº¦é™çº§</strong></li>
</ol>
<p>éšç€å±‚æ•°å¢åŠ é€æ­¥é™ä½ç²¾åº¦ï¼š</p>
<pre class="codehilite"><code>Precision(layer_i) = {
    FP32, if i &lt; 0.1L  # å‰10%å±‚
    FP16, if 0.1L â‰¤ i &lt; 0.5L  # ä¸­é—´40%å±‚
    INT8, if i â‰¥ 0.5L  # å50%å±‚
}
</code></pre>

<p>ç†è®ºä¾æ®ï¼šæ·±å±‚ç‰¹å¾æ›´åŠ æŠ½è±¡ï¼Œå¯¹ç²¾åº¦è¦æ±‚é™ä½</p>
<ol start="3">
<li><strong>æ³¨æ„åŠ›å¤´çº§åˆ«çš„æ··åˆç²¾åº¦</strong></li>
</ol>
<p>ä¸åŒæ³¨æ„åŠ›å¤´çš„é‡è¦æ€§å·®å¼‚å…è®¸å·®å¼‚åŒ–å¤„ç†ï¼š</p>
<pre class="codehilite"><code># åŸºäºæ³¨æ„åŠ›ç†µçš„é‡è¦æ€§è¯„åˆ†
Importance_h = -Î£ p_h(i,j) Ã— log(p_h(i,j))

# ç²¾åº¦åˆ†é…
Precision_h = {
    FP16, if Importance_h &gt; Î¸_high
    INT8, if Î¸_low &lt; Importance_h â‰¤ Î¸_high
    INT4, if Importance_h â‰¤ Î¸_low
}
</code></pre>

<ol start="4">
<li><strong>æ··åˆç²¾åº¦çš„å†…å­˜å¸ƒå±€</strong></li>
</ol>
<p>ä¼˜åŒ–å†…å­˜è®¿é—®æ•ˆç‡ï¼š</p>
<pre class="codehilite"><code>struct MixedPrecisionTensor {
    int8_t* int8_data;      // INT8éƒ¨åˆ†
    half* fp16_data;        // FP16éƒ¨åˆ†
    float* fp32_data;       // FP32éƒ¨åˆ†
    uint32_t* precision_map; // ç²¾åº¦æ˜ å°„
}
</code></pre>

<p>è®¿é—®ä¼˜åŒ–ï¼šå°†ç›¸åŒç²¾åº¦çš„æ•°æ®è¿ç»­å­˜å‚¨</p>
<h3 id="1633">16.3.3 åŠ¨æ€ç²¾åº¦åˆ‡æ¢æœºåˆ¶</h3>
<p>æ ¹æ®è¿è¡Œæ—¶ä¿¡æ¯åŠ¨æ€è°ƒæ•´ç²¾åº¦ï¼Œå®ç°æ€§èƒ½ä¸è´¨é‡çš„æœ€ä¼˜å¹³è¡¡ã€‚</p>
<ol>
<li><strong>åŸºäºåºåˆ—é•¿åº¦çš„åŠ¨æ€åˆ‡æ¢</strong></li>
</ol>
<p>é•¿åºåˆ—æ›´å®¹æ˜“è§¦å‘å†…å­˜ç“¶é¢ˆï¼Œéœ€è¦æ›´æ¿€è¿›çš„é‡åŒ–ï¼š</p>
<pre class="codehilite"><code>Precision = {
    FP16, if seq_len &lt; 128
    INT8, if 128 â‰¤ seq_len &lt; 512
    INT4, if seq_len â‰¥ 512
}
</code></pre>

<p>åˆ‡æ¢å¼€é”€åˆ†æï¼š</p>
<pre class="codehilite"><code>Switch_cost = Conversion_time + Cache_invalidation
</code></pre>

<ol start="2">
<li><strong>åŸºäºè®¡ç®—èµ„æºçš„è‡ªé€‚åº”</strong></li>
</ol>
<p>ç›‘æ§GPU/NPUåˆ©ç”¨ç‡åŠ¨æ€è°ƒæ•´ï¼š</p>
<pre class="codehilite"><code>if (GPU_utilization &gt; 90%):
    decrease_precision()
elif (GPU_utilization &lt; 50%):
    increase_precision()
</code></pre>

<p>å¹³æ»‘åˆ‡æ¢ç­–ç•¥é¿å…æŒ¯è¡ï¼š</p>
<pre class="codehilite"><code>Precision_t = Î± Ã— Precision_(t-1) + (1-Î±) Ã— Target_precision
</code></pre>

<ol start="3">
<li><strong>è´¨é‡ç›‘æ§ä¸å›é€€æœºåˆ¶</strong></li>
</ol>
<p>å®æ—¶ç›‘æ§è¾“å‡ºè´¨é‡ï¼Œå¿…è¦æ—¶å›é€€åˆ°é«˜ç²¾åº¦ï¼š</p>
<pre class="codehilite"><code># ç›‘æ§æŒ‡æ ‡
confidence = min(top_k_probs)
entropy = -Î£ p_i Ã— log(p_i)

# å›é€€æ¡ä»¶
if (confidence &lt; Î¸_conf or entropy &gt; Î¸_entropy):
    rollback_to_high_precision()
</code></pre>

<ol start="4">
<li><strong>é¢„å¡«å……-ç”Ÿæˆç²¾åº¦è½¬æ¢</strong></li>
</ol>
<p>é¢„å¡«å……å®Œæˆååˆ‡æ¢åˆ°ç”Ÿæˆé˜¶æ®µçš„ç²¾åº¦é…ç½®ï¼š</p>
<pre class="codehilite"><code># é¢„å¡«å……é…ç½®ï¼ˆæ¿€è¿›ï¼‰
Prefill_config = {
    &quot;attention&quot;: INT8,
    &quot;ffn&quot;: INT8,
    &quot;kv_cache&quot;: FP16
}

# ç”Ÿæˆé…ç½®ï¼ˆä¿å®ˆï¼‰
Generation_config = {
    &quot;attention&quot;: FP16,
    &quot;ffn&quot;: FP16,
    &quot;kv_cache&quot;: FP16
}
</code></pre>

<p>è½¬æ¢æ—¶æœºï¼šå®ŒæˆKV Cacheå†™å…¥å</p>
<h3 id="1634">16.3.4 ç¡¬ä»¶åŠ é€Ÿå™¨çš„é€‚é…</h3>
<p>ä¸åŒç¡¬ä»¶åŠ é€Ÿå™¨å¯¹æ··åˆç²¾åº¦çš„æ”¯æŒå·®å¼‚å¾ˆå¤§ï¼Œéœ€è¦é’ˆå¯¹æ€§ä¼˜åŒ–ã€‚</p>
<ol>
<li><strong>TensorCore/MatrixCoreåˆ©ç”¨</strong></li>
</ol>
<p>ç°ä»£GPUçš„å¼ é‡æ ¸å¿ƒå¯¹ç‰¹å®šç²¾åº¦ç»„åˆæœ‰ä¼˜åŒ–ï¼š</p>
<pre class="codehilite"><code># NVIDIA TensorCoreæ”¯æŒçš„ç»„åˆ
TC_configs = [
    (FP16, FP16, FP16),  # è¾“å…¥A, è¾“å…¥B, è¾“å‡ºC
    (FP16, FP16, FP32),
    (INT8, INT8, INT32),
    (TF32, TF32, FP32)
]

# é€‰æ‹©æœ€ä¼˜é…ç½®
best_config = max(TC_configs, key=lambda c: throughput(c))
</code></pre>

<ol start="2">
<li><strong>é‡åŒ–å¼•æ“çš„ååŒè®¾è®¡</strong></li>
</ol>
<p>ä¸ç¡¬ä»¶é‡åŒ–å•å…ƒé…åˆï¼š</p>
<pre class="codehilite"><code># Qualcomm HTAé‡åŒ–æ¨¡å¼
Quantization_mode = {
    &quot;symmetric&quot;: True,      # å¯¹ç§°é‡åŒ–
    &quot;per_channel&quot;: True,    # é€šé“çº§é‡åŒ–
    &quot;bit_width&quot;: 8,         # é‡åŒ–ä½å®½
    &quot;calibration&quot;: &quot;percentile&quot;  # æ ¡å‡†æ–¹æ³•
}
</code></pre>

<ol start="3">
<li><strong>æ··åˆç²¾åº¦çš„ç®—å­è°ƒåº¦</strong></li>
</ol>
<p>æ ¹æ®ç¡¬ä»¶ç‰¹æ€§è°ƒåº¦ä¸åŒç²¾åº¦çš„ç®—å­ï¼š</p>
<pre class="codehilite"><code># ARM big.LITTLEæ¶æ„
Schedule = {
    &quot;FP32_ops&quot;: &quot;big_cores&quot;,     # å¤§æ ¸å¤„ç†é«˜ç²¾åº¦
    &quot;INT8_ops&quot;: &quot;LITTLE_cores&quot;,  # å°æ ¸å¤„ç†ä½ç²¾åº¦
    &quot;FP16_ops&quot;: &quot;GPU&quot;            # GPUå¤„ç†ä¸­ç­‰ç²¾åº¦
}
</code></pre>

<ol start="4">
<li><strong>å†…å­˜å±‚æ¬¡çš„ç²¾åº¦é€‚é…</strong></li>
</ol>
<p>åˆ©ç”¨ä¸åŒå±‚æ¬¡çš„å†…å­˜å­˜å‚¨ä¸åŒç²¾åº¦æ•°æ®ï¼š</p>
<pre class="codehilite"><code>Memory_hierarchy = {
    &quot;L1_cache&quot;: INT4_weights,    # æœ€é¢‘ç¹è®¿é—®
    &quot;L2_cache&quot;: INT8_weights,    
    &quot;DRAM&quot;: FP16_weights,        # å®Œæ•´ç²¾åº¦å¤‡ä»½
    &quot;Storage&quot;: FP32_weights      # åŸå§‹æ¨¡å‹
}
</code></pre>

<p>ç²¾åº¦è½¬æ¢å‘ç”Ÿåœ¨æ•°æ®ç§»åŠ¨æ—¶ï¼š</p>
<pre class="codehilite"><code>On_cache_miss(address):
    higher_precision = load_from_next_level(address)
    lower_precision = quantize(higher_precision)
    store_in_cache(lower_precision)
</code></pre>

<h2 id="164-chunkedstreaming-prefill">16.4 Chunked/Streaming PrefillæŠ€æœ¯</h2>
<p>ä¼ ç»Ÿçš„é¢„å¡«å……æ–¹æ³•éœ€è¦ä¸€æ¬¡æ€§å¤„ç†æ•´ä¸ªè¾“å…¥åºåˆ—ï¼Œè¿™åœ¨é•¿åºåˆ—åœºæ™¯ä¸‹ä¼šå¯¼è‡´æ˜¾è‘—çš„é¦–Tokenå»¶è¿Ÿã€‚Chunked/Streaming PrefillæŠ€æœ¯é€šè¿‡å°†è¾“å…¥åºåˆ—åˆ†å—å¤„ç†ï¼Œå®ç°äº†å»¶è¿Ÿä¸ååé‡çš„æ›´å¥½å¹³è¡¡ã€‚</p>
<h3 id="1641">16.4.1 åˆ†å—é¢„å¡«å……çš„åŸç†</h3>
<p>åˆ†å—é¢„å¡«å……å°†é•¿åºåˆ—åˆ†è§£ä¸ºå¤šä¸ªå°å—é€æ­¥å¤„ç†ï¼Œåœ¨ä¿æŒè®¡ç®—æ•ˆç‡çš„åŒæ—¶æ˜¾è‘—é™ä½é¦–Tokenå»¶è¿Ÿã€‚</p>
<ol>
<li><strong>åŸºæœ¬æ€æƒ³ä¸åŠ¨æœº</strong></li>
</ol>
<p>ä¼ ç»Ÿé¢„å¡«å……çš„å»¶è¿Ÿç‰¹æ€§ï¼š</p>
<pre class="codehilite"><code>TTFT_traditional = O(n Ã— L Ã— dÂ²)
</code></pre>

<p>å…¶ä¸­nä¸ºåºåˆ—é•¿åº¦ï¼ŒLä¸ºå±‚æ•°ï¼Œdä¸ºéšè—ç»´åº¦ã€‚</p>
<p>åˆ†å—é¢„å¡«å……å°†åºåˆ—åˆ†ä¸ºkä¸ªå—ï¼Œæ¯å—å¤§å°ä¸ºc = n/kï¼š</p>
<pre class="codehilite"><code>TTFT_chunked = O(c Ã— L Ã— dÂ²) = O(n/k Ã— L Ã— dÂ²)
</code></pre>

<p>ç†è®ºä¸Šå¯ä»¥å°†TTFTé™ä½kå€ï¼Œä½†éœ€è¦è€ƒè™‘é¢å¤–å¼€é”€ã€‚</p>
<ol start="2">
<li><strong>æ³¨æ„åŠ›æœºåˆ¶çš„åˆ†å—è®¡ç®—</strong></li>
</ol>
<p>æ ‡å‡†è‡ªæ³¨æ„åŠ›è®¡ç®—ï¼š</p>
<pre class="codehilite"><code>Attention(Q, K, V) = softmax(QK^T/âˆšd) Ã— V
</code></pre>

<p>åˆ†å—è®¡ç®—éœ€è¦å¤„ç†è·¨å—ä¾èµ–ã€‚è®¾è¾“å…¥åºåˆ—åˆ†ä¸ºkä¸ªå—ï¼šX = [Xâ‚, Xâ‚‚, ..., Xâ‚–]</p>
<p>å¯¹äºç¬¬iä¸ªå—çš„æ³¨æ„åŠ›è®¡ç®—ï¼š</p>
<pre class="codehilite"><code>Q_i = X_i Ã— W_q
K_[:i] = [X_1; ...; X_i] Ã— W_k  # æ‰€æœ‰å·²å¤„ç†å—çš„K
V_[:i] = [X_1; ...; X_i] Ã— W_v  # æ‰€æœ‰å·²å¤„ç†å—çš„V

Attention_i = softmax(Q_i Ã— K_[:i]^T / âˆšd) Ã— V_[:i]
</code></pre>

<p>å…³é”®æ´å¯Ÿï¼šæ¯ä¸ªå—çš„æŸ¥è¯¢ï¼ˆQï¼‰åªéœ€è¦ä¸ä¹‹å‰æ‰€æœ‰å—çš„é”®å€¼ï¼ˆKVï¼‰äº¤äº’ã€‚</p>
<ol start="3">
<li><strong>å› æœæ©ç çš„å¢é‡æ›´æ–°</strong></li>
</ol>
<p>åˆ†å—å¤„ç†éœ€è¦æ­£ç¡®ç»´æŠ¤å› æœæ©ç ï¼š</p>
<pre class="codehilite"><code>Mask[i,j] = {
    1, if j â‰¤ i  # å¯ä»¥çœ‹åˆ°ä¹‹å‰çš„token
    0, if j &gt; i  # ä¸èƒ½çœ‹åˆ°æœªæ¥çš„token
}
</code></pre>

<p>å¯¹äºå—çº§åˆ«çš„æ©ç ï¼š</p>
<pre class="codehilite"><code>BlockMask[block_i, block_j] = {
    FULL,     if block_j &lt; block_i    # å®Œå…¨å¯è§
    PARTIAL,  if block_j == block_i   # å—å†…å› æœæ©ç 
    ZERO,     if block_j &gt; block_i    # å®Œå…¨ä¸å¯è§
}
</code></pre>

<ol start="4">
<li><strong>æ•°å­¦åˆ†æï¼šç²¾åº¦ä¸æ•ˆç‡æƒè¡¡</strong></li>
</ol>
<p>åˆ†å—è®¡ç®—å¼•å…¥çš„è¯¯å·®ä¸»è¦æ¥è‡ªSoftmaxçš„å½’ä¸€åŒ–ï¼š</p>
<p>åŸå§‹è®¡ç®—ï¼š</p>
<pre class="codehilite"><code>softmax(x)_i = exp(x_i) / Î£_j exp(x_j)
</code></pre>

<p>åˆ†å—è¿‘ä¼¼ï¼š</p>
<pre class="codehilite"><code>softmax_chunked(x)_i â‰ˆ exp(x_i) / (Î£_{jâˆˆprocessed} exp(x_j))
</code></pre>

<p>è¯¯å·®ä¸Šç•Œï¼š</p>
<pre class="codehilite"><code>|softmax(x)_i - softmax_chunked(x)_i| â‰¤ exp(-c) Ã— (k-1)/k
</code></pre>

<p>å…¶ä¸­cä¸ºå—å¤§å°ã€‚å—è¶Šå¤§ï¼Œè¿‘ä¼¼è¶Šç²¾ç¡®ã€‚</p>
<ol start="5">
<li><strong>KV Cacheçš„å¢é‡æ„å»º</strong></li>
</ol>
<p>åˆ†å—é¢„å¡«å……çš„æ ¸å¿ƒä¼˜åŠ¿åœ¨äºKV Cacheçš„å¢é‡æ„å»ºï¼š</p>
<pre class="codehilite"><code># ä¼ ç»Ÿæ–¹æ³•ï¼šä¸€æ¬¡æ€§æ„å»º
KV_Cache = compute_kv(X[1:n])  # O(n)å»¶è¿Ÿ

# åˆ†å—æ–¹æ³•ï¼šå¢é‡æ„å»º
for i in range(k):
    KV_Cache[i*c:(i+1)*c] = compute_kv(X[i*c:(i+1)*c])  # O(c)å»¶è¿Ÿ
    if i == 0:
        return first_token  # æå‰è¿”å›
</code></pre>

<p>å†…å­˜å†™å…¥æ¨¡å¼ä»çªå‘å†™å…¥å˜ä¸ºæµå¼å†™å…¥ï¼Œæ›´é€‚åˆè¾¹ç¼˜è®¾å¤‡çš„å†…å­˜ç³»ç»Ÿã€‚</p>
<ol start="6">
<li><strong>å¹¶è¡ŒåŒ–æœºä¼š</strong></li>
</ol>
<p>åˆ†å—å¤„ç†åˆ›é€ äº†æ–°çš„å¹¶è¡ŒåŒ–æœºä¼šï¼š</p>
<ul>
<li>å—å†…å¹¶è¡Œï¼šæ¯ä¸ªå—å†…çš„tokenä»ç„¶å¯ä»¥å¹¶è¡Œå¤„ç†</li>
<li>æµæ°´çº¿å¹¶è¡Œï¼šä¸åŒå±‚å¯ä»¥å¤„ç†ä¸åŒçš„å—</li>
<li>é¢„è®¡ç®—å¹¶è¡Œï¼šä¸‹ä¸€å—çš„KVå¯ä»¥ä¸å½“å‰å—çš„æ³¨æ„åŠ›è®¡ç®—å¹¶è¡Œ</li>
</ul>
<p>å¹¶è¡Œæ•ˆç‡åˆ†æï¼š</p>
<pre class="codehilite"><code>Efficiency = (Useful_computation) / (Total_time)
           = 1 - (Pipeline_bubble / Total_time)
           = 1 - (L-1)/(k+L-1)
</code></pre>

<p>å½“å—æ•°k &gt;&gt; Læ—¶ï¼Œæ•ˆç‡æ¥è¿‘100%ã€‚</p>
<h3 id="1642">16.4.2 æµå¼å¤„ç†æ¶æ„è®¾è®¡</h3>
<p>æµå¼å¤„ç†æ¶æ„æ˜¯å®ç°ä½å»¶è¿Ÿæ¨ç†çš„å…³é”®ï¼Œéœ€è¦ä»ç³»ç»Ÿå±‚é¢é‡æ–°è®¾è®¡æ•°æ®æµå’Œè®¡ç®—æµç¨‹ã€‚</p>
<ol>
<li><strong>æµæ°´çº¿æ¶æ„è®¾è®¡</strong></li>
</ol>
<p>ä¸‰é˜¶æ®µæµæ°´çº¿è®¾è®¡ï¼š</p>
<pre class="codehilite"><code>Stage 1: Preprocessing

- Tokenization (å¯ä»¥æµå¼)
- Embedding lookup
- Position encoding

Stage 2: Transformer Blocks

- Attention computation
- FFN computation
- KV Cache update

Stage 3: Token Generation

- Logits computation
- Sampling
- Detokenization
</code></pre>

<p>æµæ°´çº¿è°ƒåº¦ï¼š</p>
<pre class="codehilite"><code>Time  | Stage 1    | Stage 2    | Stage 3
------|------------|------------|------------
tâ‚€    | Blockâ‚     | -          | -
tâ‚    | Blockâ‚‚     | Blockâ‚     | -
tâ‚‚    | Blockâ‚ƒ     | Blockâ‚‚     | Blockâ‚(ç”Ÿæˆ)
...   | ...        | ...        | ...
</code></pre>

<ol start="2">
<li><strong>ç¯å½¢ç¼“å†²åŒºè®¾è®¡</strong></li>
</ol>
<p>é«˜æ•ˆçš„æ•°æ®ç»“æ„å¯¹æµå¼å¤„ç†è‡³å…³é‡è¦ï¼š</p>
<pre class="codehilite"><code>class RingBuffer:
    capacity: int  # æœ€å¤§å®¹é‡
    head: int      # å†™å…¥ä½ç½®
    tail: int      # è¯»å–ä½ç½®

    # å…³é”®å±æ€§
    available_space = (capacity - (head - tail)) % capacity
    available_data = (head - tail) % capacity
</code></pre>

<p>KV Cacheçš„ç¯å½¢ç¼“å†²å®ç°ï¼š</p>
<pre class="codehilite"><code>KV_RingBuffer = {
    &quot;K&quot;: RingBuffer(max_seq_len Ã— d Ã— L),
    &quot;V&quot;: RingBuffer(max_seq_len Ã— d Ã— L),
    &quot;position_map&quot;: [...]  # ä½ç½®æ˜ å°„
}
</code></pre>

<p>ä¼˜åŠ¿ï¼š</p>
<ul>
<li>æ— éœ€ç§»åŠ¨æ•°æ®</li>
<li>O(1)çš„æ’å…¥å’Œåˆ é™¤</li>
<li>è‡ªç„¶æ”¯æŒæ»‘åŠ¨çª—å£</li>
</ul>
<ol start="3">
<li><strong>å¼‚æ­¥è®¡ç®—æ¨¡å¼</strong></li>
</ol>
<p>è®¾è®¡å¼‚æ­¥è®¡ç®—æµç¨‹æœ€å¤§åŒ–ç¡¬ä»¶åˆ©ç”¨ç‡ï¼š</p>
<pre class="codehilite"><code># è®¡ç®—ä¸IOé‡å 
async def streaming_prefill():
    futures = []

    for chunk in chunks:
        # å¼‚æ­¥æäº¤è®¡ç®—ä»»åŠ¡
        future = submit_compute(chunk)
        futures.append(future)

        # å¤„ç†å®Œæˆçš„ç»“æœ
        for completed in as_completed(futures):
            result = completed.result()
            update_kv_cache(result)

            if is_first_chunk(completed):
                yield generate_first_token()
</code></pre>

<ol start="4">
<li><strong>å†…å­˜ç®¡ç†ç­–ç•¥</strong></li>
</ol>
<p>æµå¼å¤„ç†çš„å†…å­˜ç®¡ç†éœ€è¦ç‰¹åˆ«è®¾è®¡ï¼š</p>
<p>åŒç¼“å†²ç­–ç•¥ï¼š</p>
<pre class="codehilite"><code>Buffer_A: å½“å‰å¤„ç†å—
Buffer_B: ä¸‹ä¸€å—é¢„åŠ è½½

while has_more_chunks():
    # å¹¶è¡Œï¼šè®¡ç®—Aï¼ŒåŠ è½½B
    parallel_execute(
        compute(Buffer_A),
        prefetch(Buffer_B)
    )
    swap(Buffer_A, Buffer_B)
</code></pre>

<p>å†…å­˜æ± è®¾è®¡ï¼š</p>
<pre class="codehilite"><code>MemoryPool = {
    &quot;activation_pool&quot;: FixedPool(batch Ã— chunk Ã— d Ã— L),
    &quot;gradient_pool&quot;: None,  # æ¨ç†ä¸éœ€è¦
    &quot;temp_pool&quot;: DynamicPool(),  # ä¸´æ—¶buffer
}
</code></pre>

<ol start="5">
<li><strong>é”™è¯¯æ¢å¤ä¸ä¸€è‡´æ€§</strong></li>
</ol>
<p>æµå¼å¤„ç†éœ€è¦å¤„ç†éƒ¨åˆ†å¤±è´¥çš„æƒ…å†µï¼š</p>
<p>æ£€æŸ¥ç‚¹æœºåˆ¶ï¼š</p>
<pre class="codehilite"><code>Checkpoint = {
    &quot;processed_chunks&quot;: int,
    &quot;kv_cache_state&quot;: bytes,
    &quot;attention_state&quot;: bytes,
    &quot;position&quot;: int
}

# æ¯å¤„ç†Nä¸ªå—ä¿å­˜æ£€æŸ¥ç‚¹
if chunk_id % checkpoint_interval == 0:
    save_checkpoint(current_state)
</code></pre>

<p>ä¸€è‡´æ€§ä¿è¯ï¼š</p>
<ul>
<li>åŸå­æ€§çš„KV Cacheæ›´æ–°</li>
<li>ç‰ˆæœ¬æ§åˆ¶çš„çŠ¶æ€ç®¡ç†</li>
<li>å¿«é€Ÿå›æ»šèƒ½åŠ›</li>
</ul>
<ol start="6">
<li><strong>è´Ÿè½½å‡è¡¡ä¸è°ƒåº¦</strong></li>
</ol>
<p>åŠ¨æ€è°ƒåº¦é€‚åº”ä¸åŒçš„è®¡ç®—èµ„æºï¼š</p>
<pre class="codehilite"><code># å·¥ä½œçªƒå–è°ƒåº¦å™¨
class WorkStealingScheduler:
    def schedule(self, chunk):
        # æ‰¾åˆ°æœ€ç©ºé—²çš„è®¡ç®—å•å…ƒ
        unit = find_least_loaded_unit()

        # è€ƒè™‘æ•°æ®å±€éƒ¨æ€§
        if has_cached_data(unit, chunk):
            priority += locality_bonus

        # åˆ†é…ä»»åŠ¡
        unit.enqueue(chunk, priority)

    def steal_work(self, idle_unit):
        # ä»æœ€å¿™çš„å•å…ƒçªƒå–ä»»åŠ¡
        busy_unit = find_most_loaded_unit()
        if busy_unit.queue_size &gt; threshold:
            task = busy_unit.dequeue_half()
            idle_unit.enqueue(task)
</code></pre>

<ol start="7">
<li><strong>ç›‘æ§ä¸è‡ªé€‚åº”</strong></li>
</ol>
<p>å®æ—¶ç›‘æ§ç³»ç»ŸçŠ¶æ€å¹¶åŠ¨æ€è°ƒæ•´ï¼š</p>
<p>å…³é”®æŒ‡æ ‡ï¼š</p>
<pre class="codehilite"><code>Metrics = {
    &quot;chunk_latency&quot;: histogram,      # å—å¤„ç†å»¶è¿Ÿ
    &quot;pipeline_efficiency&quot;: gauge,    # æµæ°´çº¿æ•ˆç‡
    &quot;memory_pressure&quot;: gauge,        # å†…å­˜å‹åŠ›
    &quot;compute_utilization&quot;: gauge,    # è®¡ç®—åˆ©ç”¨ç‡
}
</code></pre>

<p>è‡ªé€‚åº”ç­–ç•¥ï¼š</p>
<pre class="codehilite"><code>if memory_pressure &gt; threshold:
    reduce_chunk_size()
elif compute_utilization &lt; threshold:
    increase_chunk_size()
</code></pre>

<h3 id="1643">16.4.3 å—å¤§å°çš„ä¼˜åŒ–ç­–ç•¥</h3>
<p>å—å¤§å°æ˜¯å½±å“æµå¼é¢„å¡«å……æ€§èƒ½çš„å…³é”®å‚æ•°ï¼Œéœ€è¦ç»¼åˆè€ƒè™‘å¤šä¸ªå› ç´ è¿›è¡Œä¼˜åŒ–ã€‚</p>
<ol>
<li><strong>ç†è®ºæœ€ä¼˜å—å¤§å°åˆ†æ</strong></li>
</ol>
<p>å»ºç«‹å—å¤§å°ä¼˜åŒ–çš„æ•°å­¦æ¨¡å‹ï¼š</p>
<p>æ€»å»¶è¿Ÿæ¨¡å‹ï¼š</p>
<pre class="codehilite"><code>Latency(c) = First_chunk_latency + Remaining_latency
           = Î±Ã—c + Î²Ã—(n-c)/throughput(c)
</code></pre>

<p>å…¶ä¸­ï¼š</p>
<ul>
<li>Î±ï¼šå•ä½tokençš„è®¡ç®—æ—¶é—´</li>
<li>Î²ï¼šæµæ°´çº¿å¹¶è¡Œæ•ˆç‡å› å­</li>
<li>throughput(c)ï¼šå—å¤§å°ä¸ºcæ—¶çš„ååé‡</li>
</ul>
<p>å¯¹cæ±‚å¯¼æ‰¾åˆ°æœ€ä¼˜å€¼ï¼š</p>
<pre class="codehilite"><code>dLatency/dc = Î± - Î²Ã—nÃ—throughput'(c)/throughputÂ²(c) = 0
</code></pre>

<p>è€ƒè™‘åˆ°throughput(c)é€šå¸¸å‘ˆç°å…ˆå¢åå¹³çš„ç‰¹æ€§ï¼š</p>
<pre class="codehilite"><code>throughput(c) = T_max Ã— (1 - exp(-c/câ‚€))
</code></pre>

<p>å¯å¾—æœ€ä¼˜å—å¤§å°ï¼š</p>
<pre class="codehilite"><code>c_opt = câ‚€ Ã— log(1 + Î±Ã—T_maxÃ—câ‚€/(Î²Ã—n))
</code></pre>

<ol start="2">
<li><strong>ç¡¬ä»¶çº¦æŸä¸‹çš„å—å¤§å°é€‰æ‹©</strong></li>
</ol>
<p>å®é™…é€‰æ‹©éœ€è¦è€ƒè™‘ç¡¬ä»¶é™åˆ¶ï¼š</p>
<p>å†…å­˜çº¦æŸï¼š</p>
<pre class="codehilite"><code>c_max_memory = Available_memory / (2Ã—LÃ—dÃ—sizeof(float))
</code></pre>

<ul>
<li>å› å­2æ¥è‡ªKV Cache</li>
<li>éœ€è¦é¢„ç•™æ¿€æ´»å€¼ç©ºé—´</li>
</ul>
<p>è®¡ç®—çº¦æŸï¼š</p>
<pre class="codehilite"><code>c_max_compute = sqrt(Peak_FLOPS Ã— Target_latency / (2Ã—LÃ—dÂ²))
</code></pre>

<p>ç¼“å­˜çº¦æŸï¼š</p>
<pre class="codehilite"><code>c_max_cache = Cache_size / (3Ã—dÃ—sizeof(float))
</code></pre>

<ul>
<li>å› å­3æ¥è‡ªQã€Kã€V</li>
</ul>
<p>å®é™…å—å¤§å°ï¼š</p>
<pre class="codehilite"><code>c_practical = min(c_opt, c_max_memory, c_max_compute, c_max_cache)
</code></pre>

<ol start="3">
<li><strong>åŠ¨æ€å—å¤§å°è°ƒæ•´ç­–ç•¥</strong></li>
</ol>
<p>æ ¹æ®è¿è¡Œæ—¶çŠ¶æ€åŠ¨æ€è°ƒæ•´å—å¤§å°ï¼š</p>
<p>åŸºäºè´Ÿè½½çš„è°ƒæ•´ï¼š</p>
<pre class="codehilite"><code># é«˜è´Ÿè½½æ—¶ä½¿ç”¨å°å—ï¼Œä½è´Ÿè½½æ—¶ä½¿ç”¨å¤§å—
c_dynamic = c_base Ã— (2 - load_factor)
</code></pre>

<p>åŸºäºåºåˆ—é•¿åº¦çš„è°ƒæ•´ï¼š</p>
<pre class="codehilite"><code>c_adaptive = {
    64,   if n &lt; 256     # çŸ­åºåˆ—å°å—
    128,  if 256 â‰¤ n &lt; 512
    256,  if 512 â‰¤ n &lt; 1024
    512,  if n â‰¥ 1024    # é•¿åºåˆ—å¤§å—
}
</code></pre>

<p>åŸºäºå»¶è¿ŸSLAçš„è°ƒæ•´ï¼š</p>
<pre class="codehilite"><code>if current_latency &gt; target_latency:
    c = c Ã— 0.8  # å‡å°å—å¤§å°
elif current_latency &lt; 0.5 Ã— target_latency:
    c = c Ã— 1.2  # å¢å¤§å—å¤§å°
</code></pre>

<ol start="4">
<li><strong>å—å¤§å°ä¸æ‰¹å¤„ç†çš„äº¤äº’</strong></li>
</ol>
<p>æ‰¹å¤„ç†æƒ…å†µä¸‹çš„å—å¤§å°ä¼˜åŒ–æ›´åŠ å¤æ‚ï¼š</p>
<p>æ‰¹å†…å¼‚æ„å¤„ç†ï¼š</p>
<pre class="codehilite"><code># ä¸åŒåºåˆ—ä½¿ç”¨ä¸åŒå—å¤§å°
for seq in batch:
    seq.chunk_size = compute_optimal_chunk_size(seq.length)
</code></pre>

<p>å—å¤§å°å¯¹é½ç­–ç•¥ï¼š</p>
<pre class="codehilite"><code># å¯¹é½åˆ°ç¡¬ä»¶å‹å¥½çš„å¤§å°
aligned_chunk_size = ceil(c / warp_size) Ã— warp_size
</code></pre>

<p>å†…å­˜æ•ˆç‡ä¼˜åŒ–ï¼š</p>
<pre class="codehilite"><code># é€‰æ‹©å—å¤§å°ä½¿å¾—æ‰¹å¤„ç†æ•ˆç‡æœ€é«˜
c_batch_opt = argmax(
    batch_size Ã— c / padding_overhead(batch_size, c)
)
</code></pre>

<ol start="5">
<li><strong>é¢„æµ‹æ¨¡å‹ä¸è‡ªåŠ¨è°ƒä¼˜</strong></li>
</ol>
<p>ä½¿ç”¨æœºå™¨å­¦ä¹ é¢„æµ‹æœ€ä¼˜å—å¤§å°ï¼š</p>
<p>ç‰¹å¾æå–ï¼š</p>
<pre class="codehilite"><code>Features = {
    &quot;seq_length&quot;: n,
    &quot;model_size&quot;: d,
    &quot;batch_size&quot;: b,
    &quot;available_memory&quot;: mem,
    &quot;current_load&quot;: load,
    &quot;hardware_type&quot;: hw_id
}
</code></pre>

<p>é¢„æµ‹æ¨¡å‹ï¼š</p>
<pre class="codehilite"><code># åŸºäºå†å²æ•°æ®è®­ç»ƒçš„å›å½’æ¨¡å‹
c_predicted = ML_model.predict(Features)
</code></pre>

<p>åœ¨çº¿å­¦ä¹ æ›´æ–°ï¼š</p>
<pre class="codehilite"><code># æ”¶é›†å®é™…æ€§èƒ½æ•°æ®
actual_performance = measure_performance(c_predicted)

# æ›´æ–°æ¨¡å‹
if abs(predicted_perf - actual_performance) &gt; threshold:
    ML_model.partial_fit(Features, actual_performance)
</code></pre>

<ol start="6">
<li><strong>å¤šçº§å—å¤§å°ç­–ç•¥</strong></li>
</ol>
<p>ä½¿ç”¨å±‚æ¬¡åŒ–çš„å—å¤§å°æé«˜çµæ´»æ€§ï¼š</p>
<pre class="codehilite"><code># å¤§å—å†…åŒ…å«å°å—
Hierarchical_chunks = {
    &quot;level_1&quot;: 512,  # å¤§å—ï¼Œç”¨äºæ‰¹å¤„ç†
    &quot;level_2&quot;: 128,  # ä¸­å—ï¼Œç”¨äºæµæ°´çº¿
    &quot;level_3&quot;: 32,   # å°å—ï¼Œç”¨äºä½å»¶è¿Ÿ
}
</code></pre>

<p>è‡ªé€‚åº”é€‰æ‹©ï¼š</p>
<pre class="codehilite"><code>if latency_critical:
    use_level_3_chunks()
elif throughput_critical:
    use_level_1_chunks()
else:
    use_level_2_chunks()
</code></pre>

<h3 id="1644-kv-cache">16.4.4 ä¸KV Cacheçš„ååŒè®¾è®¡</h3>
<p>åˆ†å—é¢„å¡«å……ä¸KV Cacheçš„ååŒè®¾è®¡æ˜¯å®ç°é«˜æ•ˆæµå¼æ¨ç†çš„å…³é”®ã€‚</p>
<ol>
<li><strong>å¢é‡KV Cacheæ„å»º</strong></li>
</ol>
<p>ä¼ ç»Ÿçš„ä¸€æ¬¡æ€§æ„å»ºvså¢é‡æ„å»ºï¼š</p>
<p>å¢é‡æ›´æ–°ç®—æ³•ï¼š</p>
<pre class="codehilite"><code># æ¯ä¸ªå—è®¡ç®—åç«‹å³æ›´æ–°
for chunk_id, chunk in enumerate(chunks):
    # è®¡ç®—å½“å‰å—çš„KV
    K_chunk = compute_key(chunk)
    V_chunk = compute_value(chunk)

    # æ›´æ–°åˆ°å…¨å±€Cache
    start_idx = chunk_id * chunk_size
    end_idx = start_idx + chunk_size
    KV_Cache.K[start_idx:end_idx] = K_chunk
    KV_Cache.V[start_idx:end_idx] = V_chunk

    # ç«‹å³å¯ç”¨äºç”Ÿæˆ
    if chunk_id == 0:
        enable_generation()
</code></pre>

<p>å†™å…¥ä¼˜åŒ–ï¼š</p>
<ul>
<li>ä½¿ç”¨å†™åˆå¹¶å‡å°‘å†…å­˜äº‹åŠ¡</li>
<li>é¢„åˆ†é…ç©ºé—´é¿å…åŠ¨æ€æ‰©å±•</li>
<li>å¯¹é½åˆ°ç¼“å­˜è¡Œè¾¹ç•Œ</li>
</ul>
<ol start="2">
<li><strong>KV Cacheçš„åˆ†ç‰‡å­˜å‚¨</strong></li>
</ol>
<p>å°†KV CacheæŒ‰å—ç»„ç»‡æé«˜è®¿é—®æ•ˆç‡ï¼š</p>
<pre class="codehilite"><code>class ChunkedKVCache:
    chunks: List[KVChunk]
    chunk_size: int

    class KVChunk:
        K: Tensor[chunk_size, num_heads, head_dim]
        V: Tensor[chunk_size, num_heads, head_dim]
        metadata: ChunkMetadata
</code></pre>

<p>è®¿é—®æ¨¡å¼ä¼˜åŒ–ï¼š</p>
<pre class="codehilite"><code># è¿ç»­å—çš„é¢„å–
def prefetch_chunks(current_chunk_id):
    next_chunks = [current_chunk_id + 1, current_chunk_id + 2]
    for chunk_id in next_chunks:
        if chunk_id &lt; num_chunks:
            cache_prefetch(chunks[chunk_id])
</code></pre>

<ol start="3">
<li><strong>å‹ç¼©ä¸ç¨€ç–åŒ–ååŒ</strong></li>
</ol>
<p>åˆ†å—å¤„ç†ä¸ºKV Cacheå‹ç¼©æä¾›äº†æœºä¼šï¼š</p>
<p>å—çº§å‹ç¼©ï¼š</p>
<pre class="codehilite"><code># å¯¹å®Œæˆçš„å—è¿›è¡Œå‹ç¼©
def compress_completed_chunk(chunk):
    if chunk.access_count &lt; threshold:
        # ä½é¢‘è®¿é—®å—ä½¿ç”¨é«˜å‹ç¼©æ¯”
        compressed = quantize_aggressive(chunk)
    else:
        # é«˜é¢‘è®¿é—®å—ä¿æŒé«˜ç²¾åº¦
        compressed = quantize_conservative(chunk)
    return compressed
</code></pre>

<p>ç¨€ç–åŒ–ç­–ç•¥ï¼š</p>
<pre class="codehilite"><code># è¯†åˆ«å¹¶ä¸¢å¼ƒä¸é‡è¦çš„KVå¯¹
def sparsify_chunk(chunk, keep_ratio=0.5):
    # è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°çš„ç´¯è®¡è´¡çŒ®
    attention_scores = compute_attention_importance(chunk)

    # ä¿ç•™æœ€é‡è¦çš„éƒ¨åˆ†
    top_k_indices = top_k(attention_scores, k=keep_ratio*chunk_size)
    sparse_chunk = chunk[top_k_indices]

    return sparse_chunk, top_k_indices
</code></pre>

<ol start="4">
<li><strong>é¢„æµ‹æ€§ç¼“å­˜ç®¡ç†</strong></li>
</ol>
<p>åŸºäºè®¿é—®æ¨¡å¼é¢„æµ‹ä¼˜åŒ–ç¼“å­˜ï¼š</p>
<p>è®¿é—®æ¨¡å¼åˆ†æï¼š</p>
<pre class="codehilite"><code># è·Ÿè¸ªKVè®¿é—®æ¨¡å¼
AccessPattern = {
    &quot;frequency&quot;: Counter(),      # è®¿é—®é¢‘ç‡
    &quot;recency&quot;: OrderedDict(),    # æœ€è¿‘è®¿é—®
    &quot;locality&quot;: SpatialMap(),    # ç©ºé—´å±€éƒ¨æ€§
}
</code></pre>

<p>é¢„æµ‹æ€§åŠ è½½ï¼š</p>
<pre class="codehilite"><code>def predictive_load(current_position):
    # åŸºäºå†å²æ¨¡å¼é¢„æµ‹æœªæ¥è®¿é—®
    predicted_positions = access_predictor(
        current_position, 
        AccessPattern
    )

    # é¢„åŠ è½½é¢„æµ‹çš„å—
    for pos in predicted_positions:
        chunk_id = pos // chunk_size
        if not is_cached(chunk_id):
            async_load(chunks[chunk_id])
</code></pre>

<ol start="5">
<li><strong>å¤šçº§ç¼“å­˜å±‚æ¬¡</strong></li>
</ol>
<p>è®¾è®¡å¤šçº§KV Cacheé€‚åº”ä¸åŒè®¿é—®é¢‘ç‡ï¼š</p>
<pre class="codehilite"><code>CacheHierarchy = {
    &quot;L1&quot;: {  # ç‰‡ä¸ŠSRAM
        &quot;capacity&quot;: 1MB,
        &quot;latency&quot;: 1cycle,
        &quot;policy&quot;: &quot;MRU&quot;  # æœ€è¿‘ä½¿ç”¨
    },
    &quot;L2&quot;: {  # ç‰‡ä¸Šç¼“å­˜
        &quot;capacity&quot;: 8MB,
        &quot;latency&quot;: 10cycles,
        &quot;policy&quot;: &quot;LFU&quot;  # æœ€é¢‘ç¹ä½¿ç”¨
    },
    &quot;L3&quot;: {  # DRAM
        &quot;capacity&quot;: &quot;unlimited&quot;,
        &quot;latency&quot;: 100cycles,
        &quot;policy&quot;: &quot;FIFO&quot;
    }
}
</code></pre>

<p>è¿ç§»ç­–ç•¥ï¼š</p>
<pre class="codehilite"><code># åŸºäºè®¿é—®çƒ­åº¦çš„è¿ç§»
def migrate_between_levels():
    # L3 -&gt; L2: çƒ­æ•°æ®ä¸Šç§»
    hot_chunks = identify_hot_chunks(L3, threshold=10)
    for chunk in hot_chunks:
        if L2.has_space():
            L2.insert(chunk)
            L3.mark_cached_elsewhere(chunk)

    # L2 -&gt; L1: æ›´çƒ­çš„æ•°æ®ç»§ç»­ä¸Šç§»
    very_hot_chunks = identify_hot_chunks(L2, threshold=50)
    for chunk in very_hot_chunks:
        if L1.has_space():
            L1.insert(chunk)
</code></pre>

<ol start="6">
<li><strong>ä¸€è‡´æ€§ä¸åŒæ­¥æœºåˆ¶</strong></li>
</ol>
<p>ç¡®ä¿åˆ†å—æ›´æ–°çš„ä¸€è‡´æ€§ï¼š</p>
<p>ç‰ˆæœ¬æ§åˆ¶ï¼š</p>
<pre class="codehilite"><code>class VersionedKVCache:
    version: int
    chunks: Dict[int, KVChunk]

    def update_chunk(self, chunk_id, new_data):
        with self.lock:
            self.chunks[chunk_id] = new_data
            self.version += 1
            self.notify_readers(chunk_id, self.version)
</code></pre>

<p>è¯»å†™åŒæ­¥ï¼š</p>
<pre class="codehilite"><code># è¯»å†™é”å®ç°
class RWLock:
    def read_lock(self, chunk_id):
        while self.writing[chunk_id]:
            wait()
        self.readers[chunk_id] += 1

    def write_lock(self, chunk_id):
        while self.readers[chunk_id] &gt; 0 or self.writing[chunk_id]:
            wait()
        self.writing[chunk_id] = True
</code></pre>

<p>åŸå­æ›´æ–°ï¼š</p>
<pre class="codehilite"><code># ä½¿ç”¨åŒç¼“å†²ç¡®ä¿åŸå­æ€§
def atomic_update(chunk_id, new_data):
    # å†™å…¥å½±å­å‰¯æœ¬
    shadow_buffer[chunk_id] = new_data

    # åŸå­åˆ‡æ¢æŒ‡é’ˆ
    atomic_swap(active_buffer[chunk_id], shadow_buffer[chunk_id])
</code></pre>

<h2 id="_1">æœ¬ç« å°ç»“</h2>
<p>æœ¬ç« æ·±å…¥æ¢è®¨äº†é¦–Tokenå»¶è¿Ÿï¼ˆTTFTï¼‰ä¼˜åŒ–çš„æ ¸å¿ƒæŠ€æœ¯ï¼Œè¿™æ˜¯æå‡å¤§è¯­è¨€æ¨¡å‹ç”¨æˆ·ä½“éªŒçš„å…³é”®ç¯èŠ‚ã€‚æˆ‘ä»¬ä»TTFTçš„æ„æˆåˆ†æå‡ºå‘ï¼Œé€æ­¥æ·±å…¥åˆ°å„ç§ä¼˜åŒ–æŠ€æœ¯çš„åŸç†ä¸å®è·µã€‚</p>
<p><strong>å…³é”®æ¦‚å¿µå›é¡¾ï¼š</strong></p>
<ol>
<li>
<p><strong>TTFTçš„ç»„æˆä¸å½±å“å› ç´ </strong>
   - TTFT = T_preprocess + T_prefill + T_generate + T_overhead
   - é¢„å¡«å……é˜¶æ®µå æ®ä¸»è¦å»¶è¿Ÿï¼Œæ˜¯ä¼˜åŒ–çš„é‡ç‚¹
   - å†…å­˜å¸¦å®½å¾€å¾€æ˜¯è¾¹ç¼˜è®¾å¤‡çš„ç“¶é¢ˆ</p>
</li>
<li>
<p><strong>é¢„å¡«å……ä¼˜åŒ–æŠ€æœ¯</strong>
   - å¹¶è¡ŒåŒ–ç­–ç•¥ï¼šåºåˆ—çº§ã€å¼ é‡çº§ã€æµæ°´çº¿çº§å¹¶è¡Œ
   - ç®—å­èåˆï¼šFlash Attentioné£æ ¼çš„èåˆæ˜¾è‘—å‡å°‘å†…å­˜è®¿é—®
   - å†…å­˜è®¿é—®ä¼˜åŒ–ï¼šæ•°æ®å¸ƒå±€ã€é¢„å–ã€å†…å­˜æ± ç®¡ç†
   - åŠ¨æ€å½¢çŠ¶é€‚é…ï¼špaddingç­–ç•¥ã€åŠ¨æ€æ‰¹å¤„ç†ã€JITç¼–è¯‘</p>
</li>
<li>
<p><strong>æ··åˆç²¾åº¦é¢„å¡«å……</strong>
   - ç²¾åº¦éœ€æ±‚åˆ†æï¼šFFN &gt; QKV &gt; Attention &gt; Softmax &gt; LayerNorm
   - å±‚çº§æ··åˆç²¾åº¦ï¼šé™æ€é…ç½®ä¸åŠ¨æ€åˆ‡æ¢ç›¸ç»“åˆ
   - ç¡¬ä»¶é€‚é…ï¼šå……åˆ†åˆ©ç”¨TensorCoreç­‰ä¸“ç”¨åŠ é€Ÿå•å…ƒ
   - ç²¾åº¦-æ€§èƒ½æƒè¡¡ï¼šé¢„å¡«å……é˜¶æ®µå¯ä»¥ä½¿ç”¨æ›´æ¿€è¿›çš„é‡åŒ–ç­–ç•¥</p>
</li>
<li>
<p><strong>Chunked/Streaming PrefillæŠ€æœ¯</strong>
   - åˆ†å—åŸç†ï¼šå°†O(n)å»¶è¿Ÿé™ä½åˆ°O(n/k)
   - æµå¼æ¶æ„ï¼šä¸‰é˜¶æ®µæµæ°´çº¿ã€ç¯å½¢ç¼“å†²ã€å¼‚æ­¥è®¡ç®—
   - å—å¤§å°ä¼˜åŒ–ï¼šç†è®ºåˆ†æä¸å®é™…çº¦æŸçš„å¹³è¡¡
   - KV CacheååŒï¼šå¢é‡æ„å»ºã€åˆ†ç‰‡å­˜å‚¨ã€å¤šçº§ç¼“å­˜</p>
</li>
</ol>
<p><strong>æ ¸å¿ƒå…¬å¼æ€»ç»“ï¼š</strong></p>
<ul>
<li>Rooflineæ¨¡å‹åˆ¤æ–­ï¼šAI &lt; P_max/BW_max æ—¶ä¸ºmemory-bound</li>
<li>æœ€ä¼˜æ‰¹å¤„ç†ç­‰å¾…æ—¶é—´ï¼št_wait* = sqrt(Î±/(Î²Ã—Î»))</li>
<li>åˆ†å—è¯¯å·®ä¸Šç•Œï¼š|error| â‰¤ exp(-c)Ã—(k-1)/k</li>
<li>æµæ°´çº¿æ•ˆç‡ï¼šEfficiency = 1 - (L-1)/(k+L-1)</li>
<li>æœ€ä¼˜å—å¤§å°ï¼šc_opt = câ‚€Ã—log(1 + Î±Ã—T_maxÃ—câ‚€/(Î²Ã—n))</li>
</ul>
<p><strong>å®è·µæŒ‡å¯¼ï¼š</strong></p>
<ol>
<li>å¯¹äºçŸ­åºåˆ—ï¼ˆ&lt;128 tokensï¼‰ï¼Œé‡ç‚¹ä¼˜åŒ–å†…å­˜è®¿é—®æ¨¡å¼</li>
<li>å¯¹äºé•¿åºåˆ—ï¼ˆ&gt;512 tokensï¼‰ï¼Œé‡‡ç”¨åˆ†å—é¢„å¡«å……æ˜¾è‘—é™ä½å»¶è¿Ÿ</li>
<li>æ··åˆç²¾åº¦ç­–ç•¥åº”æ ¹æ®ç¡¬ä»¶èƒ½åŠ›å’Œè´¨é‡è¦æ±‚åŠ¨æ€è°ƒæ•´</li>
<li>æµå¼å¤„ç†æ¶æ„ç‰¹åˆ«é€‚åˆå®æ—¶äº¤äº’åœºæ™¯</li>
</ol>
<p>é€šè¿‡æœ¬ç« çš„å­¦ä¹ ï¼Œè¯»è€…åº”è¯¥èƒ½å¤Ÿï¼š</p>
<ul>
<li>åˆ†æç‰¹å®šåœºæ™¯ä¸‹çš„TTFTç“¶é¢ˆ</li>
<li>é€‰æ‹©åˆé€‚çš„ä¼˜åŒ–æŠ€æœ¯ç»„åˆ</li>
<li>è®¾è®¡é«˜æ•ˆçš„é¢„å¡«å……æµæ°´çº¿</li>
<li>å®ç°ç”Ÿäº§çº§çš„ä½å»¶è¿Ÿæ¨ç†ç³»ç»Ÿ</li>
</ul>
<h2 id="_2">ç»ƒä¹ é¢˜</h2>
<h3 id="_3">åŸºç¡€é¢˜</h3>
<ol>
<li><strong>TTFTç»„æˆåˆ†æ</strong>
è®¡ç®—ä¸€ä¸ª7Bå‚æ•°æ¨¡å‹ï¼ˆd=4096, L=32, n_heads=32ï¼‰å¤„ç†512ä¸ªtokenè¾“å…¥æ—¶ï¼Œé¢„å¡«å……é˜¶æ®µçš„ç†è®ºFLOPsã€‚å‡è®¾ä½¿ç”¨æ ‡å‡†Transformeræ¶æ„ï¼ŒFFNéšè—å±‚ç»´åº¦ä¸º4dã€‚</li>
</ol>
<p><em>Hint: åˆ†åˆ«è®¡ç®—Attentionå’ŒFFNçš„FLOPsï¼Œæ³¨æ„QKVæŠ•å½±å’Œè¾“å‡ºæŠ•å½±ã€‚</em></p>
<ol start="2">
<li><strong>å†…å­˜å¸¦å®½éœ€æ±‚</strong>
åœ¨ä¸Šè¿°æ¨¡å‹é…ç½®ä¸‹ï¼Œå¦‚æœç›®æ ‡TTFTä¸º100msï¼Œè®¡ç®—æ‰€éœ€çš„æœ€å°å†…å­˜å¸¦å®½ã€‚å‡è®¾ä½¿ç”¨FP16ç²¾åº¦ï¼Œæ‰¹å¤§å°ä¸º1ã€‚</li>
</ol>
<p><em>Hint: è®¡ç®—æƒé‡è¯»å–ã€æ¿€æ´»å€¼è¯»å†™ã€KV Cacheå†™å…¥çš„æ€»æ•°æ®é‡ã€‚</em></p>
<ol start="3">
<li><strong>å—å¤§å°é€‰æ‹©</strong>
ç»™å®šå†…å­˜å¸¦å®½50GB/sï¼Œè®¡ç®—å³°å€¼1 TFLOPSï¼ˆFP16ï¼‰ï¼Œç¼“å­˜å¤§å°8MBï¼Œé’ˆå¯¹åºåˆ—é•¿åº¦n=1024ï¼Œè®¡ç®—åˆç†çš„å—å¤§å°èŒƒå›´ã€‚</li>
</ol>
<p><em>Hint: åˆ†åˆ«ä»å†…å­˜ã€è®¡ç®—ã€ç¼“å­˜çº¦æŸè®¡ç®—ä¸Šé™ï¼Œå–æœ€å°å€¼ã€‚</em></p>
<ol start="4">
<li><strong>æ··åˆç²¾åº¦é…ç½®</strong>
è®¾è®¡ä¸€ä¸ª32å±‚æ¨¡å‹çš„æ··åˆç²¾åº¦æ–¹æ¡ˆï¼Œè¦æ±‚perplexityå¢åŠ ä¸è¶…è¿‡0.15%ã€‚å·²çŸ¥ï¼šFFNä½¿ç”¨INT8å¢åŠ 0.1%ï¼ŒAttentionä½¿ç”¨FP16å¢åŠ 0.05%ï¼Œå…¨éƒ¨FP16å¢åŠ 0.2%ã€‚</li>
</ol>
<p><em>Hint: è€ƒè™‘æ¸è¿›å¼ç²¾åº¦é™çº§ç­–ç•¥ã€‚</em></p>
<h3 id="_4">æŒ‘æˆ˜é¢˜</h3>
<ol start="5">
<li><strong>æµæ°´çº¿æ•ˆç‡ä¼˜åŒ–</strong>
è®¾è®¡ä¸€ä¸ªè‡ªé€‚åº”æµæ°´çº¿è°ƒåº¦ç®—æ³•ï¼Œä½¿å¾—åœ¨å˜é•¿è¾“å…¥ï¼ˆ64-2048 tokensï¼‰æƒ…å†µä¸‹ï¼Œæµæ°´çº¿æ•ˆç‡å§‹ç»ˆä¿æŒåœ¨85%ä»¥ä¸Šã€‚è€ƒè™‘3çº§æµæ°´çº¿ï¼Œæ¯çº§å¤„ç†æ—¶é—´æ¯”ä¾‹ä¸º1:8:1ã€‚</li>
</ol>
<p><em>Hint: è€ƒè™‘åŠ¨æ€è°ƒæ•´å—å¤§å°å’Œæµæ°´çº¿æ·±åº¦ï¼Œå»ºç«‹æ•ˆç‡ä¸å—æ•°ã€æµæ°´çº¿çº§æ•°çš„å…³ç³»æ¨¡å‹ã€‚</em></p>
<ol start="6">
<li><strong>KV Cacheå‹ç¼©ç­–ç•¥</strong>
æå‡ºä¸€ç§åŸºäºæ³¨æ„åŠ›æ¨¡å¼çš„KV Cacheå‹ç¼©æ–¹æ¡ˆï¼Œè¦æ±‚ï¼š</li>
</ol>
<ul>
<li>å‹ç¼©ç‡è¾¾åˆ°4:1</li>
<li>è´¨é‡æŸå¤±æ§åˆ¶åœ¨1% perplexityä»¥å†…</li>
<li>æ”¯æŒå¢é‡æ›´æ–°</li>
<li>è®¿é—®å»¶è¿Ÿå¢åŠ ä¸è¶…è¿‡20%</li>
</ul>
<p><em>Hint: è€ƒè™‘ç»“åˆç¨€ç–åŒ–ã€é‡åŒ–å’Œé¢„æµ‹æ€§ç¼“å­˜ç®¡ç†ã€‚åˆ†æä¸åŒå±‚ã€ä¸åŒå¤´çš„æ³¨æ„åŠ›æ¨¡å¼å·®å¼‚ã€‚</em></p>
<ol start="7">
<li><strong>ç«¯åˆ°ç«¯TTFTä¼˜åŒ–</strong>
ä¸ºä¸€ä¸ªè¾¹ç¼˜éƒ¨ç½²åœºæ™¯ï¼ˆARM Cortex-A78 + Mali G78ï¼Œ8GB RAMï¼‰è®¾è®¡å®Œæ•´çš„TTFTä¼˜åŒ–æ–¹æ¡ˆã€‚æ¨¡å‹ä¸º2.7Bå‚æ•°ï¼Œç›®æ ‡TTFT &lt; 200msï¼Œæ”¯æŒæ‰¹å¤§å°4ï¼Œæœ€å¤§åºåˆ—é•¿åº¦2048ã€‚</li>
</ol>
<p><em>Hint: ç»¼åˆè€ƒè™‘æ‰€æœ‰ä¼˜åŒ–æŠ€æœ¯ï¼ŒåŒ…æ‹¬ç¡¬ä»¶ç‰¹æ€§ã€å†…å­˜å±‚æ¬¡ã€å¹¶è¡Œç­–ç•¥ç­‰ã€‚æä¾›è¯¦ç»†çš„æŠ€æœ¯é€‰æ‹©ç†ç”±å’Œé¢„æœŸæ€§èƒ½åˆ†æã€‚</em></p>
<ol start="8">
<li><strong>ç†è®ºåˆ†æé¢˜</strong>
è¯æ˜åœ¨å†…å­˜å¸¦å®½å—é™çš„æƒ…å†µä¸‹ï¼Œå­˜åœ¨ä¸€ä¸ªæœ€ä¼˜çš„é¢„å¡«å……å—å¤§å°c<em>ï¼Œä½¿å¾—ç«¯åˆ°ç«¯å»¶è¿Ÿæœ€å°ã€‚æ¨å¯¼c</em>ä¸æ¨¡å‹å‚æ•°ã€ç¡¬ä»¶å‚æ•°çš„å…³ç³»ï¼Œå¹¶è®¨è®ºè¯¥ç†è®ºç»“æœçš„å®é™…åº”ç”¨é™åˆ¶ã€‚</li>
</ol>
<p><em>Hint: å»ºç«‹åŒ…å«è®¡ç®—æ—¶é—´ã€å†…å­˜ä¼ è¾“æ—¶é—´ã€æµæ°´çº¿å¼€é”€çš„å®Œæ•´æ¨¡å‹ã€‚ä½¿ç”¨æ‹‰æ ¼æœ—æ—¥ä¹˜æ•°æ³•å¤„ç†çº¦æŸæ¡ä»¶ã€‚</em></p>
<details>
<summary>ç­”æ¡ˆæç¤º</summary>
<ol>
<li>FLOPs â‰ˆ 537.9Bï¼ˆAttention: 150.9B, FFN: 387Bï¼‰</li>
<li>æœ€å°å¸¦å®½ â‰ˆ 65.5 GB/s</li>
<li>åˆç†å—å¤§å°èŒƒå›´ï¼š128-256 tokens</li>
<li>å‰8å±‚FP32ï¼Œä¸­16å±‚FP16ï¼Œå8å±‚INT8</li>
<li>å…³é”®ï¼šå—å¤§å°ä¸åºåˆ—é•¿åº¦çš„æ˜ å°„å‡½æ•°ï¼Œè€ƒè™‘ç¡¬ä»¶åˆ‡æ¢å¼€é”€</li>
<li>ç»“åˆtop-kç¨€ç–ï¼ˆä¿ç•™25%ï¼‰+ INT8é‡åŒ– + é¢„æµ‹æ€§åŠ è½½</li>
<li>é‡‡ç”¨128 tokenå—å¤§å°ï¼Œ2çº§æµæ°´çº¿ï¼Œæ··åˆINT8/FP16ï¼ŒåŠ¨æ€æ‰¹å¤„ç†</li>
<li>c* = sqrt(BW_maxÃ—T_target/(2Ã—ÏÃ—L))ï¼Œå…¶ä¸­Ïä¸ºå†…å­˜è®¿é—®å¯†åº¦</li>
</ol>
</details>
            </article>
            
            <nav class="page-nav"><a href="chapter15.html" class="nav-link prev">â† ç¬¬15ç« ï¼šè§£ç åŠ é€ŸæŠ€æœ¯</a><a href="chapter17.html" class="nav-link next">ç¬¬17ç« ï¼šå†…å­˜ç®¡ç†ä¸Offloading â†’</a></nav>
        </main>
    </div>
</body>
</html>