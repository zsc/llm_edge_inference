# 第10章：稀疏化与参数共享

稀疏化和参数共享是模型压缩领域的两大核心技术。稀疏化通过将部分权重置零来减少计算量，而参数共享则通过复用权重来降低模型参数量。本章将深入探讨结构化稀疏、模型合并等前沿技术，重点关注它们在边缘推理场景中的实际应用。我们将从数学原理出发，详细分析各种方法的设计思想、硬件适配性以及实际部署中的权衡。

## 10.1 2:4结构化稀疏

### 10.1.1 基本概念与定义

2:4结构化稀疏是NVIDIA在Ampere架构中引入的细粒度结构化剪枝技术。其核心约束是：在每4个连续权重中，必须有且仅有2个权重为零。

对于权重矩阵 W ∈ ℝ^(m×n)，我们将其按行展开，每4个元素为一组：
- 组 G_i = [w_{i,4j}, w_{i,4j+1}, w_{i,4j+2}, w_{i,4j+3}]
- 约束：||G_i||_0 = 2，即每组恰好有2个非零元素

这种模式实现了固定的50%稀疏率，同时保持了硬件友好的规则性。

### 10.1.2 数学原理与优化目标

2:4稀疏化过程可以形式化为一个组合优化问题。对于每个4元素组，我们需要选择保留哪2个权重：

**优化目标：**
$$\min_{\mathcal{M}} \mathcal{L}(f(X; W \odot \mathcal{M}))$$

其中：
- $\mathcal{M}$ 是稀疏掩码，$\mathcal{M}_{ij} \in \{0,1\}$
- $\odot$ 表示逐元素乘积
- $\mathcal{L}$ 是损失函数
- 约束：每4个连续元素中恰好2个为1

**贪心近似算法：**
实践中采用基于幅值的贪心策略：
1. 对每组 G_i，计算权重幅值：|w_{i,j}|
2. 保留幅值最大的2个权重，其余置零
3. 生成稀疏掩码：$\mathcal{M}_{i,j} = \mathbb{1}[w_{i,j} \in \text{Top-2}(G_i)]$

### 10.1.3 硬件加速机制

NVIDIA Ampere架构引入了专门的稀疏张量核心（Sparse Tensor Cores），实现了2:4稀疏的硬件级加速。

**压缩存储格式：**
- 非零值数组：存储2个非零权重值
- 索引元数据：3比特编码6种可能的位置组合
- 存储效率：相比稠密存储减少50%

**计算流程：**
1. **数据加载**：从内存读取压缩的权重和索引
2. **动态路由**：硬件根据索引将非零权重路由到计算单元
3. **跳过零计算**：完全避免零值乘法操作
4. **吞吐量提升**：理论上可达2倍，实际1.3-1.7倍

### 10.1.4 精度恢复策略

直接剪枝会导致精度下降，需要通过微调恢复：

**渐进式稀疏化：**
$$W^{(t+1)} = W^{(t)} - \eta \nabla_W \mathcal{L} \cdot \mathcal{M}^{(t)}$$

其中稀疏掩码 $\mathcal{M}^{(t)}$ 在训练过程中逐步更新：
- 初期：允许更多权重参与更新
- 中期：逐步固定2:4模式
- 后期：仅更新非零权重

**知识蒸馏增强：**
使用稠密教师模型指导稀疏学生模型：
$$\mathcal{L}_{total} = \mathcal{L}_{task} + \lambda \mathcal{L}_{KD}(f_{sparse}, f_{dense})$$

### 10.1.5 与其他稀疏模式的对比

| 稀疏模式 | 稀疏率 | 硬件支持 | 精度保持 | 实际加速比 |
|---------|--------|----------|----------|------------|
| 2:4结构化 | 50% | 专用硬件 | 优秀 | 1.3-1.7x |
| 1:4结构化 | 75% | 理论可行 | 较差 | - |
| 块稀疏(8×8) | 灵活 | 部分支持 | 良好 | 1.2-1.5x |
| 非结构化 | 任意 | 困难 | 最佳 | <1x(通常) |

## 10.2 N:M稀疏模式设计

### 10.2.1 通用N:M稀疏框架

N:M稀疏是2:4模式的推广，表示每M个权重中保留N个非零值。稀疏率为 $s = 1 - N/M$。

**设计空间探索：**
- **细粒度**：M较小（如4, 8），硬件实现简单，但灵活性受限
- **粗粒度**：M较大（如16, 32），更灵活但硬件复杂度增加
- **混合粒度**：不同层使用不同的N:M配置

### 10.2.2 最优N:M配置选择

选择N:M配置需要平衡多个因素：

**信息论视角：**
每M个位置选N个的组合数：$C(M,N) = \binom{M}{N}$

索引开销（比特）：$\lceil \log_2 C(M,N) \rceil$

**硬件效率分析：**
- 索引解码复杂度：O(log M)
- 路由网络复杂度：O(M × N)
- 缓存行对齐：M应为缓存行大小的因子

**经验法则：**
1. M = 2^k（如4, 8, 16）便于硬件实现
2. N/M ≈ 0.5 在精度和压缩间取得平衡
3. 考虑目标硬件的SIMD宽度

### 10.2.3 自适应N:M稀疏

不同层对稀疏的敏感度不同，可以采用自适应策略：

**层级敏感度分析：**
使用泰勒展开估计剪枝影响：
$$\Delta \mathcal{L} \approx \sum_i \frac{\partial \mathcal{L}}{\partial w_i} \Delta w_i + \frac{1}{2} \sum_{i,j} \frac{\partial^2 \mathcal{L}}{\partial w_i \partial w_j} \Delta w_i \Delta w_j$$

**混合精度稀疏分配：**
- 第一层/最后层：较低稀疏率（如2:4）
- 中间层：较高稀疏率（如1:4或2:8）
- 注意力层：保守稀疏（如3:4）

### 10.2.4 块结构化稀疏

将N:M模式扩展到二维块：

**块稀疏定义：**
将权重矩阵分割为 B×B 的块，每个块要么全零要么保留。

**优势：**
- 更好的缓存局部性
- 适合矩阵乘法的分块算法
- 可利用现有的稠密计算核

**实现细节：**
```
块大小选择：
- GPU：通常 16×16 或 32×32
- CPU：8×8 或 16×16
- 考虑向量指令宽度
```

## 10.3 共享参数与模型合并

### 10.3.1 模型合并的数学基础

模型合并通过组合多个独立训练的模型来创建一个多功能模型。

**权重空间的几何视角：**
神经网络的损失景观存在多个局部最优点，这些点可能通过低损失路径相连。

**线性模式连接性（LMC）：**
给定两个模型 θ_1 和 θ_2，探索连接路径：
$$θ(α) = (1-α)θ_1 + αθ_2, \quad α \in [0,1]$$

如果 $\mathcal{L}(θ(α))$ 在整个区间保持较低值，说明存在线性连接性。

### 10.3.2 任务算术（Task Arithmetic）

任务算术将模型能力向量化，实现灵活的能力组合。

**任务向量定义：**
$$\tau_i = θ_{task_i} - θ_{base}$$

其中：
- $θ_{base}$：预训练基础模型
- $θ_{task_i}$：在任务i上微调后的模型
- $\tau_i$：任务i的"技能向量"

**算术操作：**
1. **能力添加**：$θ_{new} = θ_{base} + \lambda(\tau_A + \tau_B)$
2. **能力增强**：$θ_{new} = θ_{base} + \lambda \cdot \tau_A$（λ > 1）
3. **能力消除**：$θ_{new} = θ_{base} - \tau_A$

### 10.3.3 高级合并算法

**TIES-Merging算法：**

1. **修剪（Trim）**：
   保留每个任务向量中变化最大的k%参数：
   $$\tilde{\tau}_i = \tau_i \odot \mathbb{1}[|\tau_i| > \text{Percentile}(|\tau_i|, 100-k)]$$

2. **选举（Elect）**：
   解决符号冲突：
   $$\text{sign}_{elected} = \text{sign}\left(\sum_i \text{sign}(\tilde{\tau}_{i,j})\right)$$

3. **解耦合并（Disjoint Merge）**：
   只合并符号一致的参数：
   $$\theta_{merged,j} = θ_{base,j} + \frac{1}{|\mathcal{A}_j|} \sum_{i \in \mathcal{A}_j} \tilde{\tau}_{i,j}$$
   
   其中 $\mathcal{A}_j$ 是在位置j上符号与选举结果一致的任务集合。

**DARE（Drop And REscale）：**

引入随机性提高泛化：
1. **随机丢弃**：$\tilde{\tau} = \tau \odot \text{Bernoulli}(1-p)$
2. **重新缩放**：$\tilde{\tau} = \tilde{\tau} / (1-p)$

这保持了期望值不变：$\mathbb{E}[\tilde{\tau}] = \tau$

### 10.3.4 边缘场景的模型合并

**存储优化策略：**

1. **基础模型 + 任务向量**：
   - 存储一个通用基础模型（如LLaMA）
   - 各任务只存储小型任务向量
   - 存储减少：~90%（任务向量通常很稀疏）

2. **动态合并**：
   ```
   推理时动态组合：
   if task == "translation":
       θ = θ_base + τ_translation
   elif task == "summarization":
       θ = θ_base + τ_summarization
   ```

**延迟优化：**
- 预计算常用任务组合
- 缓存合并后的权重
- 使用量化的任务向量（INT8/INT4）

## 10.4 稀疏张量的高效存储

### 10.4.1 稀疏存储格式

**COO（Coordinate）格式：**
存储三个数组：
- 行索引：row_indices[]
- 列索引：col_indices[]
- 非零值：values[]

存储开销：$O(nnz \times (2 \times \text{sizeof}(int) + \text{sizeof}(float)))$

**CSR（Compressed Sparse Row）格式：**
- 行指针：row_ptr[]（长度m+1）
- 列索引：col_indices[]（长度nnz）
- 非零值：values[]（长度nnz）

优势：行访问高效，适合矩阵-向量乘法

**块稀疏格式：**
将矩阵分块，只存储非零块：
- 块索引：block_indices[]
- 块数据：block_values[]（每个块密集存储）

### 10.4.2 硬件友好的稀疏格式

**2:4格式编码：**
```
原始：[0.1, 0, 0, 0.3] 
编码：
- 值：[0.1, 0.3]
- 索引：0b1001（二进制表示位置）
```

**向量化友好格式：**
对齐到SIMD宽度（如AVX-512的512位）：
- 将多个2:4组打包到一个向量寄存器
- 使用掩码寄存器进行选择性加载/存储

### 10.4.3 压缩技术集成

**量化 + 稀疏：**
1. 先进行2:4稀疏化
2. 对非零值进行INT8/INT4量化
3. 总压缩率：50%（稀疏）× 25%（INT8）= 12.5%

**聚类 + 稀疏：**
- 对非零权重进行K-means聚类
- 存储聚类中心和索引
- 适合权重分布有明显模式的情况

### 10.4.4 动态稀疏管理

**稀疏模式缓存：**
```
缓存结构：
- 模式ID -> 稀疏掩码
- LRU替换策略
- 预计算常见模式
```

**增量更新：**
对于在线学习场景，支持稀疏模式的增量更新：
$$\mathcal{M}^{(t+1)} = \alpha \mathcal{M}^{(t)} + (1-α) \mathcal{M}_{new}$$

## 本章小结

本章深入探讨了稀疏化和参数共享两大模型压缩技术：

1. **2:4结构化稀疏**：通过硬件-算法协同设计，实现了50%压缩率和1.3-1.7倍实际加速。其成功关键在于规则的稀疏模式使硬件能够高效跳过零计算。

2. **N:M稀疏设计**：提供了灵活的稀疏配置空间，需要在硬件复杂度、压缩率和精度间权衡。自适应和混合粒度策略可以进一步优化性能。

3. **模型合并技术**：从简单的权重平均到复杂的任务算术，提供了低成本的多任务模型构建方案。TIES-Merging和DARE等方法解决了参数冲突问题。

4. **稀疏存储优化**：不同的稀疏格式适用于不同场景，硬件友好的格式设计是实现加速的关键。量化与稀疏的结合可以达到极高的压缩率。

关键公式回顾：
- 2:4稀疏约束：$||G_i||_0 = 2$ for each 4-element group
- 任务向量：$\tau = θ_{task} - θ_{base}$
- TIES符号选举：$\text{sign}_{elected} = \text{sign}(\sum_i \text{sign}(\tau_i))$
- 存储效率：压缩率 = 稀疏率 × 量化压缩率

## 练习题

### 基础题

1. **2:4稀疏计算**
   给定权重向量 [0.5, -0.2, 0.8, -0.1, 0.3, 0.7, -0.6, 0.4]，应用2:4稀疏化。计算稀疏化后的向量和所需的索引位数。
   
   *Hint: 每4个元素为一组，保留绝对值最大的2个。*

2. **稀疏存储分析**
   一个 1024×1024 的矩阵采用2:4稀疏，使用FP16存储。计算采用COO格式和2:4专用格式的存储需求（字节）。
   
   *Hint: 2:4格式每4个元素需要2个FP16值和3比特索引。*

3. **任务向量计算**
   基础模型参数 θ_base = [1.0, 2.0, 3.0]，两个任务微调后的参数分别为 θ_A = [1.2, 2.1, 2.8] 和 θ_B = [0.9, 2.3, 3.1]。计算任务向量并执行任务算术 θ_base + 0.5(τ_A + τ_B)。
   
   *Hint: 先计算每个任务向量，然后进行线性组合。*

4. **N:M配置选择**
   对于一个要求75%稀疏率的场景，列出所有可能的N:M配置（M≤8），并计算各自的索引开销。
   
   *Hint: 稀疏率 = 1 - N/M = 0.75*

### 挑战题

5. **混合稀疏优化**
   设计一个神经网络的层级稀疏方案：网络有10层，第1层和第10层对精度最敏感，中间层可以承受更高稀疏。在总体稀疏率达到60%的约束下，如何分配各层的N:M配置？
   
   *Hint: 考虑使用拉格朗日乘数法优化分配。*

6. **TIES-Merging分析**
   三个任务向量在某参数位置的更新分别为：τ_1 = +0.5, τ_2 = -0.3, τ_3 = +0.2。使用TIES-Merging的选举和合并策略，计算最终的参数更新。如果先应用50%的修剪阈值会如何影响结果？
   
   *Hint: 考虑符号投票和选择性平均。*

7. **稀疏模式的信息论分析**
   证明2:4稀疏模式的索引信息熵上界为log₂(6)比特。推广到一般的N:M稀疏，导出索引熵的公式。这对硬件设计有什么启示？
   
   *Hint: 使用组合数学和信息论基础。*

8. **动态稀疏调度**
   设计一个算法，在推理时根据输入的特征动态选择不同层的稀疏模式。目标是在保持精度的同时最大化吞吐量。考虑：如何快速评估每层的重要性？如何避免模式切换的开销？
   
   *Hint: 可以使用输入相关的敏感度度量，如梯度范数或激活值统计。*

<details>
<summary>答案（点击展开）</summary>

1. 稀疏化结果：[0.5, 0, 0.8, 0], [0, 0.7, -0.6, 0]。每组需要3比特索引，总共6比特。

2. COO格式：3×524,288×2 = 3,145,728字节。2:4格式：2×262,144×2 + 262,144×3/8 = 1,147,192字节。

3. τ_A = [0.2, 0.1, -0.2], τ_B = [-0.1, 0.3, 0.1]。结果：[1.05, 2.2, 2.95]。

4. 1:4（索引2比特）、2:8（索引约6.6比特）、3:12等，具体计算略。

5. 示例方案：第1、10层用3:4（25%稀疏），第2-9层用1:3（66.7%稀疏），总体约60%。

6. 符号投票：2正1负，选正。合并：(0.5+0.2)/2=0.35。修剪后可能只保留τ_1。

7. C(4,2)=6种组合，熵上界log₂(6)≈2.58比特。一般公式：H ≤ log₂(C(M,N))。

8. 算法框架：计算各层激活范数→映射到稀疏等级→缓存常用模式→批量切换。

</details>